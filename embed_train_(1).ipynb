{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ofAiden/Duplicate-Charged-Particle-Tracks-with-ML-professor-Tuna/blob/main/embed_train_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHQwVxv57eXV",
        "outputId": "f90748ab-3ad9-4a83-d125-c947d4daa46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2026.1.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading data_file.root from Google Drive...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1l0NvKngLrY7HZxx69ZrnLYEWWvTwmM5f\n",
            "From (redirected): https://drive.google.com/uc?id=1l0NvKngLrY7HZxx69ZrnLYEWWvTwmM5f&confirm=t&uuid=612a1198-8759-46bf-92f0-6f3e33ff9257\n",
            "To: /content/data_file.root\n",
            "100%|██████████| 3.42G/3.42G [00:52<00:00, 65.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branches: ['sim_pt', 'sim_eta', 'sim_phi', 'sim_pca_dxy', 'sim_pca_dz', 'sim_q', 'sim_event', 'sim_pdgId', 'sim_vx', 'sim_vy', 'sim_vz', 'sim_trkNtupIdx', 'sim_TC_matched', 'sim_TC_matched_mask', 'tc_pt', 'tc_eta', 'tc_phi', 'tc_type', 'tc_isFake', 'tc_isDuplicate', 'tc_matched_simIdx', 'sim_dummy', 'tc_dummy', 'pT5_matched_simIdx', 'pT5_hitIdxs', 'sim_pT5_matched', 'pT5_pt', 'pT5_eta', 'pT5_phi', 'pT5_isFake', 't5_sim_vxy', 't5_sim_vz', 'pT5_isDuplicate', 'pT5_score', 'pT5_layer_binary', 'pT5_moduleType_binary', 'pT5_matched_pt', 'pT5_rzChiSquared', 'pT5_rPhiChiSquared', 'pT5_rPhiChiSquaredInwards', 'sim_pT3_matched', 'pT3_pt', 'pT3_isFake', 'pT3_isDuplicate', 'pT3_eta', 'pT3_phi', 'pT3_score', 'pT3_foundDuplicate', 'pT3_matched_simIdx', 'pT3_hitIdxs', 'pT3_pixelRadius', 'pT3_pixelRadiusError', 'pT3_matched_pt', 'pT3_tripletRadius', 'pT3_rPhiChiSquared', 'pT3_rPhiChiSquaredInwards', 'pT3_rzChiSquared', 'pT3_layer_binary', 'pT3_moduleType_binary', 'sim_pLS_matched', 'pLS_matched_simIdx', 'pLS_isFake', 'pLS_isDuplicate', 'pLS_ptIn', 'pLS_ptErr', 'pLS_px', 'pLS_py', 'pLS_pz', 'pLS_x', 'pLS_y', 'pLS_z', 'pLS_eta', 'pLS_isQuad', 'pLS_charge', 'pLS_deltaPhi', 'pLS_etaErr', 'pLS_phi', 'pLS_score', 'pLS_circleCenterX', 'pLS_circleCenterY', 'pLS_circleRadius', 'sim_T5_matched', 't5_isFake', 't5_isDuplicate', 't5_foundDuplicate', 't5_pt', 't5_pMatched', 't5_eta', 't5_phi', 't5_score_rphisum', 't5_hitIdxs', 't5_matched_simIdx', 't5_moduleType_binary', 't5_layer_binary', 't5_matched_pt', 't5_innerRadius', 't5_outerRadius', 't5_bridgeRadius', 't5_chiSquared', 't5_rzChiSquared', 't5_isDupAlgoFlag', 't5_nonAnchorChiSquared', 't5_dBeta1', 't5_dBeta2', 'module_layers', 'module_subdets', 'module_rings', 'module_rods', 'module_modules', 'module_isTilted', 'module_eta', 'module_r', 'md_occupancies', 'sg_occupancies', 't3_occupancies', 'tc_occupancies', 't5_occupancies', 'pT3_occupancies', 'pT5_occupancies', 't5_t3_idx0', 't5_t3_idx1', 't5_tc_idx', 't5_partOfTC', 't5_t3_pt', 't5_t3_eta', 't5_t3_phi', 't5_t3_fakeScore1', 't5_t3_promptScore1', 't5_t3_displacedScore1', 't5_t3_fakeScore2', 't5_t3_promptScore2', 't5_t3_displacedScore2', 't5_t3_0_r', 't5_t3_0_x', 't5_t3_0_y', 't5_t3_0_z', 't5_t3_0_eta', 't5_t3_0_phi', 't5_t3_0_detId', 't5_t3_0_layer', 't5_t3_0_moduleType', 't5_t3_1_r', 't5_t3_1_x', 't5_t3_1_y', 't5_t3_1_z', 't5_t3_1_eta', 't5_t3_1_phi', 't5_t3_1_detId', 't5_t3_1_layer', 't5_t3_1_moduleType', 't5_t3_2_r', 't5_t3_2_x', 't5_t3_2_y', 't5_t3_2_z', 't5_t3_2_eta', 't5_t3_2_phi', 't5_t3_2_detId', 't5_t3_2_layer', 't5_t3_2_moduleType', 't5_t3_3_r', 't5_t3_3_x', 't5_t3_3_y', 't5_t3_3_z', 't5_t3_3_eta', 't5_t3_3_phi', 't5_t3_3_detId', 't5_t3_3_layer', 't5_t3_3_moduleType', 't5_t3_4_r', 't5_t3_4_x', 't5_t3_4_y', 't5_t3_4_z', 't5_t3_4_eta', 't5_t3_4_phi', 't5_t3_4_detId', 't5_t3_4_layer', 't5_t3_4_moduleType', 't5_t3_5_r', 't5_t3_5_x', 't5_t3_5_y', 't5_t3_5_z', 't5_t3_5_eta', 't5_t3_5_phi', 't5_t3_5_detId', 't5_t3_5_layer', 't5_t3_5_moduleType', 't3_betaIn', 't3_centerX', 't3_centerY', 't3_radius', 't3_partOfPT5', 't3_partOfT5', 't3_partOfPT3', 't3_pMatched', 't3_sim_vxy', 't3_sim_vz', 't3_hit_0_r', 't3_hit_0_x', 't3_hit_0_y', 't3_hit_0_z', 't3_hit_0_eta', 't3_hit_0_phi', 't3_hit_0_detId', 't3_hit_0_layer', 't3_hit_0_moduleType', 't3_hit_1_r', 't3_hit_1_x', 't3_hit_1_y', 't3_hit_1_z', 't3_hit_1_eta', 't3_hit_1_phi', 't3_hit_1_detId', 't3_hit_1_layer', 't3_hit_1_moduleType', 't3_hit_2_r', 't3_hit_2_x', 't3_hit_2_y', 't3_hit_2_z', 't3_hit_2_eta', 't3_hit_2_phi', 't3_hit_2_detId', 't3_hit_2_layer', 't3_hit_2_moduleType', 't3_hit_3_r', 't3_hit_3_x', 't3_hit_3_y', 't3_hit_3_z', 't3_hit_3_eta', 't3_hit_3_phi', 't3_hit_3_detId', 't3_hit_3_layer', 't3_hit_3_moduleType', 't3_hit_4_r', 't3_hit_4_x', 't3_hit_4_y', 't3_hit_4_z', 't3_hit_4_eta', 't3_hit_4_phi', 't3_hit_4_detId', 't3_hit_4_layer', 't3_hit_4_moduleType', 't3_hit_5_r', 't3_hit_5_x', 't3_hit_5_y', 't3_hit_5_z', 't3_hit_5_eta', 't3_hit_5_phi', 't3_hit_5_detId', 't3_hit_5_layer', 't3_hit_5_moduleType', 't3_layer_binary', 't3_matched_simIdx']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import uproot\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "import awkward as ak # Using awkward array for easier handling of jagged data\n",
        "import time # For timing steps\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "seed_value = 42\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "\n",
        "def load_root_file(file_path, branches=None, print_branches=False):\n",
        "    all_branches = {}\n",
        "    with uproot.open(file_path) as file:\n",
        "        tree = file[\"tree\"]\n",
        "        # Load all ROOT branches into array if not specified\n",
        "        if branches is None:\n",
        "            branches = tree.keys()\n",
        "        # Option to print the branch names\n",
        "        if print_branches:\n",
        "            print(\"Branches:\", tree.keys())\n",
        "        # Each branch is added to the dictionary\n",
        "        for branch in branches:\n",
        "            try:\n",
        "                all_branches[branch] = (tree[branch].array(library=\"np\"))\n",
        "            except uproot.KeyInFileError as e:\n",
        "                print(f\"KeyInFileError: {e}\")\n",
        "        # Number of events in file\n",
        "        all_branches['event'] = tree.num_entries\n",
        "    return all_branches\n",
        "\n",
        "branches_list = [\n",
        "    't5_innerRadius',\n",
        "    't5_bridgeRadius',\n",
        "    't5_outerRadius',\n",
        "    't5_pt',\n",
        "    't5_eta',\n",
        "    't5_phi',\n",
        "    't5_isFake',\n",
        "    't5_t3_idx0',\n",
        "    't5_t3_idx1',\n",
        "\n",
        "    't5_t3_fakeScore1',\n",
        "    't5_t3_promptScore1',\n",
        "    't5_t3_displacedScore1',\n",
        "    't5_t3_fakeScore2',\n",
        "    't5_t3_promptScore2',\n",
        "    't5_t3_displacedScore2',\n",
        "\n",
        "    't5_pMatched',\n",
        "    't5_sim_vxy',\n",
        "    't5_sim_vz',\n",
        "    't5_matched_simIdx'\n",
        "]\n",
        "\n",
        "branches_list += [\n",
        "    'pLS_eta',\n",
        "    'pLS_etaErr',\n",
        "    'pLS_phi',\n",
        "    'pLS_matched_simIdx',\n",
        "    'pLS_circleCenterX',\n",
        "    'pLS_circleCenterY',\n",
        "    'pLS_circleRadius',\n",
        "    'pLS_ptIn',\n",
        "    'pLS_ptErr',\n",
        "    'pLS_px',\n",
        "    'pLS_py',\n",
        "    'pLS_pz',\n",
        "    'pLS_isQuad',\n",
        "    'pLS_isFake'\n",
        "]\n",
        "\n",
        "# Hit-dependent branches\n",
        "suffixes = ['r', 'z', 'eta', 'phi', 'layer']\n",
        "branches_list += [f't5_t3_{i}_{suffix}' for i in [0, 2, 4] for suffix in suffixes]\n",
        "\n",
        "!pip install gdown\n",
        "\n",
        "import gdown\n",
        "\n",
        "# 1. The Google Drive File ID (found in the shareable link)\n",
        "# Example: if link is https://drive.google.com/file/d/1ABC123.../view, ID is '1ABC123...'\n",
        "file_id = '1l0NvKngLrY7HZxx69ZrnLYEWWvTwmM5f'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "# 2. Where you want to save the file locally\n",
        "file_path = 'data_file.root'\n",
        "\n",
        "# 3. Download logic\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Downloading {file_path} from Google Drive...\")\n",
        "    gdown.download(url, file_path, quiet=False)\n",
        "else:\n",
        "    print(f\"File '{file_path}' already exists locally. Skipping download.\")\n",
        "\n",
        "branches = load_root_file(file_path, branches_list, print_branches=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMz4NKdc7eXW",
        "outputId": "61d98fbf-0804-4113-d74a-321427619229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z max: 267.2349853515625, R max: 110.10993957519531, Eta max: 2.5\n"
          ]
        }
      ],
      "source": [
        "z_max = np.max([np.max(event) for event in branches[f't5_t3_4_z']])\n",
        "r_max = np.max([np.max(event) for event in branches[f't5_t3_4_r']])\n",
        "eta_max = 2.5\n",
        "phi_max = np.pi\n",
        "n_events = np.shape(branches['t5_pt'])[0]\n",
        "\n",
        "print(f'Z max: {z_max}, R max: {r_max}, Eta max: {eta_max}')\n",
        "\n",
        "def delta_phi(phi1, phi2):\n",
        "    delta = phi1 - phi2\n",
        "    # Adjust delta to be within the range [-pi, pi]\n",
        "    if delta > np.pi:\n",
        "        delta -= 2 * np.pi\n",
        "    elif delta < -np.pi:\n",
        "        delta += 2 * np.pi\n",
        "    return delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aHBCDYrX7eXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13c3549-6598-4737-a2bd-cb90fc737563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Building T5 features  (pMatched ≥ 0.0) …\n",
            "\n",
            "Kept 3630781 / 3630781 T5s (100.00 %) that passed the pMatched cut.\n",
            "Total events with ≥1 kept T5: 500\n"
          ]
        }
      ],
      "source": [
        "pMATCHED_THRESHOLD = 0.        # keep if t5_pMatched ≥ this\n",
        "print(f\"\\nBuilding T5 features  (pMatched ≥ {pMATCHED_THRESHOLD}) …\")\n",
        "\n",
        "features_per_event    = []\n",
        "eta_per_event         = []\n",
        "displaced_per_event = []\n",
        "sim_indices_per_event = []\n",
        "\n",
        "kept_tot, init_tot = 0, 0\n",
        "for ev in range(n_events):\n",
        "\n",
        "    n_t5 = len(branches['t5_t3_idx0'][ev])\n",
        "    init_tot += n_t5\n",
        "    if n_t5 == 0:\n",
        "        continue\n",
        "\n",
        "    feat_evt = []\n",
        "    eta_evt  = []\n",
        "    sim_evt  = []\n",
        "    disp_evt = []\n",
        "\n",
        "    for i in range(n_t5):\n",
        "        if branches['t5_pMatched'][ev][i] < pMATCHED_THRESHOLD:\n",
        "            continue\n",
        "\n",
        "        idx0 = branches['t5_t3_idx0'][ev][i]\n",
        "        idx1 = branches['t5_t3_idx1'][ev][i]\n",
        "\n",
        "        # hit-level quantities -------------------------------------------------\n",
        "        eta1 = (branches['t5_t3_0_eta'][ev][idx0])\n",
        "        eta2 = abs(branches['t5_t3_2_eta'][ev][idx0])\n",
        "        eta3 = abs(branches['t5_t3_4_eta'][ev][idx0])\n",
        "        eta4 = abs(branches['t5_t3_2_eta'][ev][idx1])\n",
        "        eta5 = abs(branches['t5_t3_4_eta'][ev][idx1])\n",
        "\n",
        "        phi1 = branches['t5_t3_0_phi'][ev][idx0]\n",
        "        phi2 = branches['t5_t3_2_phi'][ev][idx0]\n",
        "        phi3 = branches['t5_t3_4_phi'][ev][idx0]\n",
        "        phi4 = branches['t5_t3_2_phi'][ev][idx1]\n",
        "        phi5 = branches['t5_t3_4_phi'][ev][idx1]\n",
        "\n",
        "        z1 = abs(branches['t5_t3_0_z'][ev][idx0])\n",
        "        z2 = abs(branches['t5_t3_2_z'][ev][idx0])\n",
        "        z3 = abs(branches['t5_t3_4_z'][ev][idx0])\n",
        "        z4 = abs(branches['t5_t3_2_z'][ev][idx1])\n",
        "        z5 = abs(branches['t5_t3_4_z'][ev][idx1])\n",
        "\n",
        "        r1 = branches['t5_t3_0_r'][ev][idx0]\n",
        "        r2 = branches['t5_t3_2_r'][ev][idx0]\n",
        "        r3 = branches['t5_t3_4_r'][ev][idx0]\n",
        "        r4 = branches['t5_t3_2_r'][ev][idx1]\n",
        "        r5 = branches['t5_t3_4_r'][ev][idx1]\n",
        "\n",
        "        inR  = branches['t5_innerRadius' ][ev][i]\n",
        "        brR  = branches['t5_bridgeRadius'][ev][i]\n",
        "        outR = branches['t5_outerRadius' ][ev][i]\n",
        "\n",
        "        s1_fake   = branches['t5_t3_fakeScore1'     ][ev][i]\n",
        "        s1_prompt = branches['t5_t3_promptScore1'   ][ev][i]\n",
        "        s1_disp   = branches['t5_t3_displacedScore1'][ev][i]\n",
        "        d_fake    = branches['t5_t3_fakeScore2'     ][ev][i] - s1_fake\n",
        "        d_prompt  = branches['t5_t3_promptScore2'   ][ev][i] - s1_prompt\n",
        "        d_disp    = branches['t5_t3_displacedScore2'][ev][i] - s1_disp\n",
        "\n",
        "        f = [\n",
        "            eta1 / eta_max,\n",
        "            np.cos(phi1),\n",
        "            np.sin(phi1),\n",
        "            z1 / z_max,\n",
        "            r1 / r_max,\n",
        "\n",
        "            eta2 - abs(eta1),\n",
        "            delta_phi(phi2, phi1),\n",
        "            (z2 - z1) / z_max,\n",
        "            (r2 - r1) / r_max,\n",
        "\n",
        "            eta3 - eta2,\n",
        "            delta_phi(phi3, phi2),\n",
        "            (z3 - z2) / z_max,\n",
        "            (r3 - r2) / r_max,\n",
        "\n",
        "            eta4 - eta3,\n",
        "            delta_phi(phi4, phi3),\n",
        "            (z4 - z3) / z_max,\n",
        "            (r4 - r3) / r_max,\n",
        "\n",
        "            eta5 - eta4,\n",
        "            delta_phi(phi5, phi4),\n",
        "            (z5 - z4) / z_max,\n",
        "            (r5 - r4) / r_max,\n",
        "\n",
        "            1.0 / inR,\n",
        "            1.0 / brR,\n",
        "            1.0 / outR,\n",
        "\n",
        "            s1_fake, s1_prompt, s1_disp,\n",
        "            d_fake,  d_prompt,  d_disp\n",
        "        ]\n",
        "        feat_evt.append(f)\n",
        "        eta_evt.append(eta1)\n",
        "        disp_evt.append(branches['t5_sim_vxy'][ev][i])\n",
        "\n",
        "        # first (or only) matched sim-index, -1 if none -----------------------\n",
        "        simIdx_list = branches['t5_matched_simIdx'][ev][i]\n",
        "        sim_evt.append(simIdx_list[0] if len(simIdx_list) else -1)\n",
        "\n",
        "    # push to global containers ----------------------------------------------\n",
        "    if feat_evt:                                # skip events with no survivors\n",
        "        features_per_event.append(np.asarray(feat_evt, dtype=np.float32))\n",
        "        eta_per_event.append(np.asarray(eta_evt,  dtype=np.float32))\n",
        "        displaced_per_event.append(np.asarray(disp_evt, dtype=np.float32))\n",
        "        sim_indices_per_event.append(np.asarray(sim_evt, dtype=np.int64))\n",
        "        kept_tot += len(feat_evt)\n",
        "\n",
        "print(f\"\\nKept {kept_tot} / {init_tot} T5s \"\n",
        "      f\"({kept_tot/init_tot*100:.2f} %) that passed the pMatched cut.\")\n",
        "print(f\"Total events with ≥1 kept T5: {len(features_per_event)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtNumH1x7eXX",
        "outputId": "b48723b9-8883-4d3b-cb0b-e8ba3d29cd32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Building pLS features …\n",
            "\n",
            "Kept 3722110 / 11314631 pLSs (32.90 %) that passed the selections.\n",
            "Total events with ≥1 kept pLS: 500\n"
          ]
        }
      ],
      "source": [
        "KEEP_FRAC_PLS = 0.40\n",
        "print(f\"\\nBuilding pLS features …\")\n",
        "\n",
        "pLS_features_per_event    = []\n",
        "pLS_eta_per_event         = []\n",
        "pLS_sim_indices_per_event = []\n",
        "\n",
        "kept_tot_pls, init_tot_pls = 0, 0\n",
        "for ev in range(n_events):\n",
        "    n_pls = len(branches['pLS_eta'][ev])\n",
        "    init_tot_pls += n_pls\n",
        "    if n_pls == 0:\n",
        "        continue\n",
        "\n",
        "    feat_evt, eta_evt, sim_evt = [], [], []\n",
        "\n",
        "    for i in range(n_pls):\n",
        "        if branches['pLS_isFake'][ev][i]:\n",
        "            continue\n",
        "        if np.random.random() > KEEP_FRAC_PLS:\n",
        "            continue\n",
        "\n",
        "        # ――― hit‑level quantities -------------------------------------------\n",
        "        eta = branches['pLS_eta'][ev][i]\n",
        "        etaErr = branches['pLS_etaErr'][ev][i]\n",
        "        phi = branches['pLS_phi'][ev][i]\n",
        "        circleCenterX = np.abs(branches['pLS_circleCenterX'][ev][i])\n",
        "        circleCenterY = np.abs(branches['pLS_circleCenterY'][ev][i])\n",
        "        circleRadius = branches['pLS_circleRadius'][ev][i]\n",
        "        ptIn = branches['pLS_ptIn'][ev][i]\n",
        "        ptErr = branches['pLS_ptErr'][ev][i]\n",
        "        isQuad = branches['pLS_isQuad'][ev][i]\n",
        "\n",
        "        # ――― build feature vector -------------------------------------------\n",
        "        f = [\n",
        "            eta/4.0,\n",
        "            etaErr/.00139,\n",
        "            np.cos(phi),\n",
        "            np.sin(phi),\n",
        "            1.0 / ptIn,\n",
        "            np.log10(ptErr),\n",
        "            isQuad,\n",
        "            np.log10(circleCenterX),\n",
        "            np.log10(circleCenterY),\n",
        "            np.log10(circleRadius),\n",
        "        ]\n",
        "\n",
        "        feat_evt.append(f)\n",
        "        eta_evt.append(eta)\n",
        "\n",
        "        sim_list = branches['pLS_matched_simIdx'][ev][i]\n",
        "        sim_evt.append(sim_list[0] if len(sim_list) else -1)\n",
        "\n",
        "    # ――― store per‑event containers -----------------------------------------\n",
        "    if feat_evt:              # skip events with no survivors\n",
        "        pLS_features_per_event   .append(np.asarray(feat_evt, dtype=np.float32))\n",
        "        pLS_eta_per_event        .append(np.asarray(eta_evt,  dtype=np.float32))\n",
        "        pLS_sim_indices_per_event.append(np.asarray(sim_evt, dtype=np.int64))\n",
        "        kept_tot_pls += len(feat_evt)\n",
        "\n",
        "print(f\"\\nKept {kept_tot_pls} / {init_tot_pls} pLSs \"\n",
        "      f\"({kept_tot_pls/init_tot_pls*100:.2f} %) that passed the selections.\")\n",
        "print(f\"Total events with ≥1 kept pLS: {len(pLS_features_per_event)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mCCzb9hZ7eXX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6ffead3-e38d-4ae8-8c1f-56e549bb3cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Pair generation  (ΔR² < 0.02)  –  parallel mode\n",
            "[evt    0]  T5s= 7083  sim=1000  dis=1000\n",
            "[evt    1]  T5s= 6400  sim=1000  dis=1000\n",
            "[evt    2]  T5s= 6708  sim=1000  dis=1000\n",
            "[evt    3]  T5s= 7768  sim=1000  dis=1000\n",
            "[evt    4]  T5s= 5870  sim=1000  dis=1000\n",
            "[evt    5]  T5s= 7422  sim=1000  dis=1000\n",
            "[evt    6]  T5s= 6374  sim=1000  dis=1000\n",
            "[evt    7]  T5s= 9034  sim=1000  dis=1000\n",
            "[evt    8]  T5s= 8741  sim=1000  dis=1000\n",
            "[evt    9]  T5s= 7114  sim=1000  dis=1000\n",
            "[evt   10]  T5s= 6965  sim=1000  dis=1000\n",
            "[evt   11]  T5s= 6277  sim=1000  dis=1000\n",
            "[evt   12]  T5s= 7587  sim=1000  dis=1000\n",
            "[evt   13]  T5s= 8697  sim=1000  dis=1000\n",
            "[evt   14]  T5s= 6359  sim=1000  dis=1000\n",
            "[evt   15]  T5s= 8403  sim=1000  dis=1000\n",
            "[evt   16]  T5s= 5981  sim=1000  dis=1000\n",
            "[evt   17]  T5s= 5930  sim=1000  dis=1000\n",
            "[evt   18]  T5s= 7760  sim=1000  dis=1000\n",
            "[evt   19]  T5s= 7765  sim=1000  dis=1000\n",
            "[evt   20]  T5s= 6925  sim=1000  dis=1000\n",
            "[evt   21]  T5s= 7230  sim=1000  dis=1000\n",
            "[evt   22]  T5s= 4984  sim=1000  dis=1000\n",
            "[evt   23]  T5s= 7603  sim=1000  dis=1000\n",
            "[evt   24]  T5s= 7119  sim=1000  dis=1000\n",
            "[evt   25]  T5s=10321  sim=1000  dis=1000\n",
            "[evt   26]  T5s= 6796  sim=1000  dis=1000\n",
            "[evt   27]  T5s= 6540  sim=1000  dis=1000\n",
            "[evt   28]  T5s= 6947  sim=1000  dis=1000\n",
            "[evt   29]  T5s= 5019  sim=1000  dis=1000\n",
            "[evt   30]  T5s= 8798  sim=1000  dis=1000\n",
            "[evt   31]  T5s= 7922  sim=1000  dis=1000\n",
            "[evt   32]  T5s= 7620  sim=1000  dis=1000\n",
            "[evt   33]  T5s= 7098  sim=1000  dis=1000\n",
            "[evt   34]  T5s= 5685  sim=1000  dis=1000\n",
            "[evt   35]  T5s= 6811  sim=1000  dis=1000\n",
            "[evt   36]  T5s= 9102  sim=1000  dis=1000\n",
            "[evt   37]  T5s= 7470  sim=1000  dis=1000\n",
            "[evt   38]  T5s= 6897  sim=1000  dis=1000\n",
            "[evt   39]  T5s= 8534  sim=1000  dis=1000\n",
            "[evt   40]  T5s= 7615  sim=1000  dis=1000\n",
            "[evt   41]  T5s= 6688  sim=1000  dis=1000\n",
            "[evt   42]  T5s= 7705  sim=1000  dis=1000\n",
            "[evt   43]  T5s= 7596  sim=1000  dis=1000\n",
            "[evt   44]  T5s= 4815  sim=1000  dis=1000\n",
            "[evt   45]  T5s= 7725  sim=1000  dis=1000\n",
            "[evt   46]  T5s= 5784  sim=1000  dis=1000\n",
            "[evt   47]  T5s= 6637  sim=1000  dis=1000\n",
            "[evt   48]  T5s= 6918  sim=1000  dis=1000\n",
            "[evt   49]  T5s= 9116  sim=1000  dis=1000\n",
            "[evt   50]  T5s= 5916  sim=1000  dis=1000\n",
            "[evt   51]  T5s= 7751  sim=1000  dis=1000\n",
            "[evt   52]  T5s= 8330  sim=1000  dis=1000\n",
            "[evt   53]  T5s= 7182  sim=1000  dis=1000\n",
            "[evt   54]  T5s= 6511  sim=1000  dis=1000\n",
            "[evt   55]  T5s= 6929  sim=1000  dis=1000\n",
            "[evt   56]  T5s= 6276  sim=1000  dis=1000\n",
            "[evt   57]  T5s= 6562  sim=1000  dis=1000\n",
            "[evt   58]  T5s= 7927  sim=1000  dis=1000\n",
            "[evt   59]  T5s= 7944  sim=1000  dis=1000\n",
            "[evt   60]  T5s= 5984  sim=1000  dis=1000\n",
            "[evt   61]  T5s= 8691  sim=1000  dis=1000\n",
            "[evt   62]  T5s= 7293  sim=1000  dis=1000\n",
            "[evt   63]  T5s= 7316  sim=1000  dis=1000\n",
            "[evt   64]  T5s= 8005  sim=1000  dis=1000\n",
            "[evt   65]  T5s= 9605  sim=1000  dis=1000\n",
            "[evt   66]  T5s= 8056  sim=1000  dis=1000\n",
            "[evt   67]  T5s= 6148  sim=1000  dis=1000\n",
            "[evt   68]  T5s= 7210  sim=1000  dis=1000\n",
            "[evt   69]  T5s= 8483  sim=1000  dis=1000\n",
            "[evt   70]  T5s= 6940  sim=1000  dis=1000\n",
            "[evt   71]  T5s= 8263  sim=1000  dis=1000\n",
            "[evt   72]  T5s= 6286  sim=1000  dis=1000\n",
            "[evt   73]  T5s= 6029  sim=1000  dis=1000\n",
            "[evt   74]  T5s= 7793  sim=1000  dis=1000\n",
            "[evt   75]  T5s= 5776  sim=1000  dis=1000\n",
            "[evt   76]  T5s= 6403  sim=1000  dis=1000\n",
            "[evt   77]  T5s= 9386  sim=1000  dis=1000\n",
            "[evt   78]  T5s= 8552  sim=1000  dis=1000\n",
            "[evt   79]  T5s=10014  sim=1000  dis=1000\n",
            "[evt   80]  T5s= 6762  sim=1000  dis=1000\n",
            "[evt   81]  T5s= 5146  sim=1000  dis=1000\n",
            "[evt   82]  T5s= 5553  sim=1000  dis=1000\n",
            "[evt   83]  T5s= 5534  sim=1000  dis=1000\n",
            "[evt   84]  T5s= 4510  sim=1000  dis=1000\n",
            "[evt   85]  T5s= 5707  sim=1000  dis=1000\n",
            "[evt   86]  T5s= 7437  sim=1000  dis=1000\n",
            "[evt   87]  T5s=11100  sim=1000  dis=1000\n",
            "[evt   88]  T5s= 8585  sim=1000  dis=1000\n",
            "[evt   89]  T5s= 5972  sim=1000  dis=1000\n",
            "[evt   90]  T5s= 7930  sim=1000  dis=1000\n",
            "[evt   91]  T5s= 7136  sim=1000  dis=1000\n",
            "[evt   92]  T5s= 7870  sim=1000  dis=1000\n",
            "[evt   93]  T5s= 5053  sim=1000  dis=1000\n",
            "[evt   94]  T5s= 6577  sim=1000  dis=1000\n",
            "[evt   95]  T5s= 7053  sim=1000  dis=1000\n",
            "[evt   96]  T5s= 6349  sim=1000  dis=1000\n",
            "[evt   97]  T5s= 8995  sim=1000  dis=1000\n",
            "[evt   98]  T5s= 7479  sim=1000  dis=1000\n",
            "[evt   99]  T5s= 8816  sim=1000  dis=1000\n",
            "[evt  100]  T5s= 6379  sim=1000  dis=1000\n",
            "[evt  101]  T5s= 6968  sim=1000  dis=1000\n",
            "[evt  102]  T5s= 6685  sim=1000  dis=1000\n",
            "[evt  103]  T5s= 7813  sim=1000  dis=1000\n",
            "[evt  104]  T5s= 8420  sim=1000  dis=1000\n",
            "[evt  105]  T5s= 5588  sim=1000  dis=1000\n",
            "[evt  106]  T5s= 6657  sim=1000  dis=1000\n",
            "[evt  107]  T5s= 9121  sim=1000  dis=1000\n",
            "[evt  108]  T5s= 8546  sim=1000  dis=1000\n",
            "[evt  109]  T5s= 6469  sim=1000  dis=1000\n",
            "[evt  110]  T5s= 6559  sim=1000  dis=1000\n",
            "[evt  111]  T5s= 7000  sim=1000  dis=1000\n",
            "[evt  112]  T5s= 8900  sim=1000  dis=1000\n",
            "[evt  113]  T5s= 7638  sim=1000  dis=1000\n",
            "[evt  114]  T5s= 7955  sim=1000  dis=1000\n",
            "[evt  115]  T5s= 7555  sim=1000  dis=1000\n",
            "[evt  116]  T5s= 8347  sim=1000  dis=1000\n",
            "[evt  117]  T5s= 6831  sim=1000  dis=1000\n",
            "[evt  118]  T5s= 6158  sim=1000  dis=1000\n",
            "[evt  119]  T5s= 6887  sim=1000  dis=1000\n",
            "[evt  120]  T5s= 8191  sim=1000  dis=1000\n",
            "[evt  121]  T5s= 7261  sim=1000  dis=1000\n",
            "[evt  122]  T5s= 8389  sim=1000  dis=1000\n",
            "[evt  123]  T5s= 6043  sim=1000  dis=1000\n",
            "[evt  124]  T5s= 7395  sim=1000  dis=1000\n",
            "[evt  125]  T5s= 9144  sim=1000  dis=1000\n",
            "[evt  126]  T5s= 9110  sim=1000  dis=1000\n",
            "[evt  127]  T5s= 8605  sim=1000  dis=1000\n",
            "[evt  128]  T5s= 6286  sim=1000  dis=1000\n",
            "[evt  129]  T5s= 6318  sim=1000  dis=1000\n",
            "[evt  130]  T5s= 8332  sim=1000  dis=1000\n",
            "[evt  131]  T5s=10845  sim=1000  dis=1000\n",
            "[evt  132]  T5s= 5303  sim=1000  dis=1000\n",
            "[evt  133]  T5s= 7656  sim=1000  dis=1000\n",
            "[evt  134]  T5s= 6735  sim=1000  dis=1000\n",
            "[evt  135]  T5s= 6024  sim=1000  dis=1000\n",
            "[evt  136]  T5s= 7858  sim=1000  dis=1000\n",
            "[evt  137]  T5s= 7341  sim=1000  dis=1000\n",
            "[evt  138]  T5s= 6301  sim=1000  dis=1000\n",
            "[evt  139]  T5s= 7712  sim=1000  dis=1000\n",
            "[evt  140]  T5s= 7321  sim=1000  dis=1000\n",
            "[evt  141]  T5s= 8266  sim=1000  dis=1000\n",
            "[evt  142]  T5s= 5267  sim=1000  dis=1000\n",
            "[evt  143]  T5s= 8373  sim=1000  dis=1000\n",
            "[evt  144]  T5s= 9235  sim=1000  dis=1000\n",
            "[evt  145]  T5s= 8026  sim=1000  dis=1000\n",
            "[evt  146]  T5s= 9557  sim=1000  dis=1000\n",
            "[evt  147]  T5s= 7224  sim=1000  dis=1000\n",
            "[evt  148]  T5s= 6556  sim=1000  dis=1000\n",
            "[evt  149]  T5s= 5170  sim=1000  dis=1000\n",
            "[evt  150]  T5s= 8062  sim=1000  dis=1000\n",
            "[evt  151]  T5s= 6091  sim=1000  dis=1000\n",
            "[evt  152]  T5s= 4838  sim=1000  dis=1000\n",
            "[evt  153]  T5s= 7025  sim=1000  dis=1000\n",
            "[evt  154]  T5s= 7551  sim=1000  dis=1000\n",
            "[evt  155]  T5s= 7031  sim=1000  dis=1000\n",
            "[evt  156]  T5s= 7721  sim=1000  dis=1000\n",
            "[evt  157]  T5s= 7669  sim=1000  dis=1000\n",
            "[evt  158]  T5s= 8318  sim=1000  dis=1000\n",
            "[evt  159]  T5s= 6415  sim=1000  dis=1000\n",
            "[evt  160]  T5s= 6334  sim=1000  dis=1000\n",
            "[evt  161]  T5s= 8452  sim=1000  dis=1000\n",
            "[evt  162]  T5s= 5685  sim=1000  dis=1000\n",
            "[evt  163]  T5s= 7619  sim=1000  dis=1000\n",
            "[evt  164]  T5s= 6834  sim=1000  dis=1000\n",
            "[evt  165]  T5s= 8140  sim=1000  dis=1000\n",
            "[evt  166]  T5s= 7002  sim=1000  dis=1000\n",
            "[evt  167]  T5s= 8450  sim=1000  dis=1000\n",
            "[evt  168]  T5s= 5986  sim=1000  dis=1000\n",
            "[evt  169]  T5s= 7724  sim=1000  dis=1000\n",
            "[evt  170]  T5s= 5591  sim=1000  dis=1000\n",
            "[evt  171]  T5s= 4953  sim=1000  dis=1000\n",
            "[evt  172]  T5s= 7191  sim=1000  dis=1000\n",
            "[evt  173]  T5s= 7944  sim=1000  dis=1000\n",
            "[evt  174]  T5s= 8204  sim=1000  dis=1000\n",
            "[evt  175]  T5s= 7088  sim=1000  dis=1000\n",
            "[evt  176]  T5s= 6067  sim=1000  dis=1000\n",
            "[evt  177]  T5s= 5966  sim=1000  dis=1000\n",
            "[evt  178]  T5s= 5337  sim=1000  dis=1000\n",
            "[evt  179]  T5s= 7730  sim=1000  dis=1000\n",
            "[evt  180]  T5s= 6047  sim=1000  dis=1000\n",
            "[evt  181]  T5s= 7999  sim=1000  dis=1000\n",
            "[evt  182]  T5s= 6584  sim=1000  dis=1000\n",
            "[evt  183]  T5s=10000  sim=1000  dis=1000\n",
            "[evt  184]  T5s= 8066  sim=1000  dis=1000\n",
            "[evt  185]  T5s= 6998  sim=1000  dis=1000\n",
            "[evt  186]  T5s= 9503  sim=1000  dis=1000\n",
            "[evt  187]  T5s= 5638  sim=1000  dis=1000\n",
            "[evt  188]  T5s= 5984  sim=1000  dis=1000\n",
            "[evt  189]  T5s= 7346  sim=1000  dis=1000\n",
            "[evt  190]  T5s= 7460  sim=1000  dis=1000\n",
            "[evt  191]  T5s= 7025  sim=1000  dis=1000\n",
            "[evt  192]  T5s= 6946  sim=1000  dis=1000\n",
            "[evt  193]  T5s= 9507  sim=1000  dis=1000\n",
            "[evt  194]  T5s= 7747  sim=1000  dis=1000\n",
            "[evt  195]  T5s= 5666  sim=1000  dis=1000\n",
            "[evt  196]  T5s= 9163  sim=1000  dis=1000\n",
            "[evt  197]  T5s= 5441  sim=1000  dis=1000\n",
            "[evt  198]  T5s= 8434  sim=1000  dis=1000\n",
            "[evt  199]  T5s= 7492  sim=1000  dis=1000\n",
            "[evt  200]  T5s= 7672  sim=1000  dis=1000\n",
            "[evt  201]  T5s= 6659  sim=1000  dis=1000\n",
            "[evt  202]  T5s= 8476  sim=1000  dis=1000\n",
            "[evt  203]  T5s= 5875  sim=1000  dis=1000\n",
            "[evt  204]  T5s= 7512  sim=1000  dis=1000\n",
            "[evt  205]  T5s= 5857  sim=1000  dis=1000\n",
            "[evt  206]  T5s= 7084  sim=1000  dis=1000\n",
            "[evt  207]  T5s= 9097  sim=1000  dis=1000\n",
            "[evt  208]  T5s= 6834  sim=1000  dis=1000\n",
            "[evt  209]  T5s= 6713  sim=1000  dis=1000\n",
            "[evt  210]  T5s= 7911  sim=1000  dis=1000\n",
            "[evt  211]  T5s= 7481  sim=1000  dis=1000\n",
            "[evt  212]  T5s= 7977  sim=1000  dis=1000\n",
            "[evt  213]  T5s= 6201  sim=1000  dis=1000\n",
            "[evt  214]  T5s= 6494  sim=1000  dis=1000\n",
            "[evt  215]  T5s= 6413  sim=1000  dis=1000\n",
            "[evt  216]  T5s= 6933  sim=1000  dis=1000\n",
            "[evt  217]  T5s= 8393  sim=1000  dis=1000\n",
            "[evt  218]  T5s= 9169  sim=1000  dis=1000\n",
            "[evt  219]  T5s= 6332  sim=1000  dis=1000\n",
            "[evt  220]  T5s= 5396  sim=1000  dis=1000\n",
            "[evt  221]  T5s= 8361  sim=1000  dis=1000\n",
            "[evt  222]  T5s= 8262  sim=1000  dis=1000\n",
            "[evt  223]  T5s= 7270  sim=1000  dis=1000\n",
            "[evt  224]  T5s= 9364  sim=1000  dis=1000\n",
            "[evt  225]  T5s= 8226  sim=1000  dis=1000\n",
            "[evt  226]  T5s= 7691  sim=1000  dis=1000\n",
            "[evt  227]  T5s= 7841  sim=1000  dis=1000\n",
            "[evt  228]  T5s= 6598  sim=1000  dis=1000\n",
            "[evt  229]  T5s= 8692  sim=1000  dis=1000\n",
            "[evt  230]  T5s= 8651  sim=1000  dis=1000\n",
            "[evt  231]  T5s= 8645  sim=1000  dis=1000\n",
            "[evt  232]  T5s= 7782  sim=1000  dis=1000\n",
            "[evt  233]  T5s= 7038  sim=1000  dis=1000\n",
            "[evt  234]  T5s= 5747  sim=1000  dis=1000\n",
            "[evt  235]  T5s= 8151  sim=1000  dis=1000\n",
            "[evt  236]  T5s= 6706  sim=1000  dis=1000\n",
            "[evt  237]  T5s= 7603  sim=1000  dis=1000\n",
            "[evt  238]  T5s= 8105  sim=1000  dis=1000\n",
            "[evt  239]  T5s= 7401  sim=1000  dis=1000\n",
            "[evt  240]  T5s= 6985  sim=1000  dis=1000\n",
            "[evt  241]  T5s= 8749  sim=1000  dis=1000\n",
            "[evt  242]  T5s= 6791  sim=1000  dis=1000\n",
            "[evt  243]  T5s= 7892  sim=1000  dis=1000\n",
            "[evt  244]  T5s= 7471  sim=1000  dis=1000\n",
            "[evt  245]  T5s= 7158  sim=1000  dis=1000\n",
            "[evt  246]  T5s= 6938  sim=1000  dis=1000\n",
            "[evt  247]  T5s= 7586  sim=1000  dis=1000\n",
            "[evt  248]  T5s= 4641  sim=1000  dis=1000\n",
            "[evt  249]  T5s=11489  sim=1000  dis=1000\n",
            "[evt  250]  T5s= 7043  sim=1000  dis=1000\n",
            "[evt  251]  T5s= 6616  sim=1000  dis=1000\n",
            "[evt  252]  T5s= 8287  sim=1000  dis=1000\n",
            "[evt  253]  T5s= 6789  sim=1000  dis=1000\n",
            "[evt  254]  T5s= 6665  sim=1000  dis=1000\n",
            "[evt  255]  T5s= 8521  sim=1000  dis=1000\n",
            "[evt  256]  T5s= 5868  sim=1000  dis=1000\n",
            "[evt  257]  T5s= 6820  sim=1000  dis=1000\n",
            "[evt  258]  T5s= 6450  sim=1000  dis=1000\n",
            "[evt  259]  T5s= 7562  sim=1000  dis=1000\n",
            "[evt  260]  T5s= 6007  sim=1000  dis=1000\n",
            "[evt  261]  T5s= 7976  sim=1000  dis=1000\n",
            "[evt  262]  T5s= 5798  sim=1000  dis=1000\n",
            "[evt  263]  T5s= 7454  sim=1000  dis=1000\n",
            "[evt  264]  T5s= 8430  sim=1000  dis=1000\n",
            "[evt  265]  T5s= 6227  sim=1000  dis=1000\n",
            "[evt  266]  T5s= 8389  sim=1000  dis=1000\n",
            "[evt  267]  T5s= 7041  sim=1000  dis=1000\n",
            "[evt  268]  T5s= 6595  sim=1000  dis=1000\n",
            "[evt  269]  T5s= 8938  sim=1000  dis=1000\n",
            "[evt  270]  T5s= 8038  sim=1000  dis=1000\n",
            "[evt  271]  T5s= 6896  sim=1000  dis=1000\n",
            "[evt  272]  T5s= 7061  sim=1000  dis=1000\n",
            "[evt  273]  T5s= 6119  sim=1000  dis=1000\n",
            "[evt  274]  T5s= 5956  sim=1000  dis=1000\n",
            "[evt  275]  T5s= 5889  sim=1000  dis=1000\n",
            "[evt  276]  T5s= 6660  sim=1000  dis=1000\n",
            "[evt  277]  T5s= 8428  sim=1000  dis=1000\n",
            "[evt  278]  T5s= 7488  sim=1000  dis=1000\n",
            "[evt  279]  T5s= 7632  sim=1000  dis=1000\n",
            "[evt  280]  T5s= 7127  sim=1000  dis=1000\n",
            "[evt  281]  T5s= 7287  sim=1000  dis=1000\n",
            "[evt  282]  T5s= 5249  sim=1000  dis=1000\n",
            "[evt  283]  T5s= 6017  sim=1000  dis=1000\n",
            "[evt  284]  T5s= 7200  sim=1000  dis=1000\n",
            "[evt  285]  T5s= 6305  sim=1000  dis=1000\n",
            "[evt  286]  T5s= 7426  sim=1000  dis=1000\n",
            "[evt  287]  T5s= 7740  sim=1000  dis=1000\n",
            "[evt  288]  T5s= 3864  sim=1000  dis=1000\n",
            "[evt  289]  T5s= 6789  sim=1000  dis=1000\n",
            "[evt  290]  T5s= 6139  sim=1000  dis=1000\n",
            "[evt  291]  T5s= 8642  sim=1000  dis=1000\n",
            "[evt  292]  T5s= 6977  sim=1000  dis=1000\n",
            "[evt  293]  T5s= 6131  sim=1000  dis=1000\n",
            "[evt  294]  T5s= 6799  sim=1000  dis=1000\n",
            "[evt  295]  T5s= 5673  sim=1000  dis=1000\n",
            "[evt  296]  T5s= 7431  sim=1000  dis=1000\n",
            "[evt  297]  T5s= 7667  sim=1000  dis=1000\n",
            "[evt  298]  T5s= 5710  sim=1000  dis=1000\n",
            "[evt  299]  T5s= 9294  sim=1000  dis=1000\n",
            "[evt  300]  T5s= 5077  sim=1000  dis=1000\n",
            "[evt  301]  T5s= 5286  sim=1000  dis=1000\n",
            "[evt  302]  T5s= 8668  sim=1000  dis=1000\n",
            "[evt  303]  T5s= 4605  sim=1000  dis=1000\n",
            "[evt  304]  T5s= 6574  sim=1000  dis=1000\n",
            "[evt  305]  T5s= 6585  sim=1000  dis=1000\n",
            "[evt  306]  T5s= 9339  sim=1000  dis=1000\n",
            "[evt  307]  T5s= 7227  sim=1000  dis=1000\n",
            "[evt  308]  T5s= 6880  sim=1000  dis=1000\n",
            "[evt  309]  T5s= 3914  sim=1000  dis=1000\n",
            "[evt  310]  T5s= 6171  sim=1000  dis=1000\n",
            "[evt  311]  T5s= 8158  sim=1000  dis=1000\n",
            "[evt  312]  T5s= 5845  sim=1000  dis=1000\n",
            "[evt  313]  T5s= 9096  sim=1000  dis=1000\n",
            "[evt  314]  T5s= 7154  sim=1000  dis=1000\n",
            "[evt  315]  T5s= 7448  sim=1000  dis=1000\n",
            "[evt  316]  T5s= 7010  sim=1000  dis=1000\n",
            "[evt  317]  T5s= 6012  sim=1000  dis=1000\n",
            "[evt  318]  T5s= 5623  sim=1000  dis=1000\n",
            "[evt  319]  T5s= 8743  sim=1000  dis=1000\n",
            "[evt  320]  T5s= 9115  sim=1000  dis=1000\n",
            "[evt  321]  T5s= 7028  sim=1000  dis=1000\n",
            "[evt  322]  T5s= 6696  sim=1000  dis=1000\n",
            "[evt  323]  T5s= 9516  sim=1000  dis=1000\n",
            "[evt  324]  T5s= 7659  sim=1000  dis=1000\n",
            "[evt  325]  T5s= 7776  sim=1000  dis=1000\n",
            "[evt  326]  T5s=10340  sim=1000  dis=1000\n",
            "[evt  327]  T5s= 4142  sim=1000  dis=1000\n",
            "[evt  328]  T5s= 7841  sim=1000  dis=1000\n",
            "[evt  329]  T5s= 5199  sim=1000  dis=1000\n",
            "[evt  330]  T5s=11341  sim=1000  dis=1000\n",
            "[evt  331]  T5s=10604  sim=1000  dis=1000\n",
            "[evt  332]  T5s= 5876  sim=1000  dis=1000\n",
            "[evt  333]  T5s= 8635  sim=1000  dis=1000\n",
            "[evt  334]  T5s= 6705  sim=1000  dis=1000\n",
            "[evt  335]  T5s= 4786  sim=1000  dis=1000\n",
            "[evt  336]  T5s= 4853  sim=1000  dis=1000\n",
            "[evt  337]  T5s= 9890  sim=1000  dis=1000\n",
            "[evt  338]  T5s= 8398  sim=1000  dis=1000\n",
            "[evt  339]  T5s= 4777  sim=1000  dis=1000\n",
            "[evt  340]  T5s= 9376  sim=1000  dis=1000\n",
            "[evt  341]  T5s= 6440  sim=1000  dis=1000\n",
            "[evt  342]  T5s= 7045  sim=1000  dis=1000\n",
            "[evt  343]  T5s= 6048  sim=1000  dis=1000\n",
            "[evt  344]  T5s= 8149  sim=1000  dis=1000\n",
            "[evt  345]  T5s= 7358  sim=1000  dis=1000\n",
            "[evt  346]  T5s= 7610  sim=1000  dis=1000\n",
            "[evt  347]  T5s= 7139  sim=1000  dis=1000\n",
            "[evt  348]  T5s= 7392  sim=1000  dis=1000\n",
            "[evt  349]  T5s= 8982  sim=1000  dis=1000\n",
            "[evt  350]  T5s= 9820  sim=1000  dis=1000\n",
            "[evt  351]  T5s= 8809  sim=1000  dis=1000\n",
            "[evt  352]  T5s= 9374  sim=1000  dis=1000\n",
            "[evt  353]  T5s= 8487  sim=1000  dis=1000\n",
            "[evt  354]  T5s= 5492  sim=1000  dis=1000\n",
            "[evt  355]  T5s= 9004  sim=1000  dis=1000\n",
            "[evt  356]  T5s= 5444  sim=1000  dis=1000\n",
            "[evt  357]  T5s= 7574  sim=1000  dis=1000\n",
            "[evt  358]  T5s= 6500  sim=1000  dis=1000\n",
            "[evt  359]  T5s= 6550  sim=1000  dis=1000\n",
            "[evt  360]  T5s= 6459  sim=1000  dis=1000\n",
            "[evt  361]  T5s= 7154  sim=1000  dis=1000\n",
            "[evt  362]  T5s= 6510  sim=1000  dis=1000\n",
            "[evt  363]  T5s= 6925  sim=1000  dis=1000\n",
            "[evt  364]  T5s= 8630  sim=1000  dis=1000\n",
            "[evt  365]  T5s= 6582  sim=1000  dis=1000\n",
            "[evt  366]  T5s= 6037  sim=1000  dis=1000\n",
            "[evt  367]  T5s= 5300  sim=1000  dis=1000\n",
            "[evt  368]  T5s= 6131  sim=1000  dis=1000\n",
            "[evt  369]  T5s= 8728  sim=1000  dis=1000\n",
            "[evt  370]  T5s= 9720  sim=1000  dis=1000\n",
            "[evt  371]  T5s= 7356  sim=1000  dis=1000\n",
            "[evt  372]  T5s= 7767  sim=1000  dis=1000\n",
            "[evt  373]  T5s= 7563  sim=1000  dis=1000\n",
            "[evt  374]  T5s= 9367  sim=1000  dis=1000\n",
            "[evt  375]  T5s= 6812  sim=1000  dis=1000\n",
            "[evt  376]  T5s= 6876  sim=1000  dis=1000\n",
            "[evt  377]  T5s= 6283  sim=1000  dis=1000\n",
            "[evt  378]  T5s= 7566  sim=1000  dis=1000\n",
            "[evt  379]  T5s= 7651  sim=1000  dis=1000\n",
            "[evt  380]  T5s= 6820  sim=1000  dis=1000\n",
            "[evt  381]  T5s= 5820  sim=1000  dis=1000\n",
            "[evt  382]  T5s= 6577  sim=1000  dis=1000\n",
            "[evt  383]  T5s= 7142  sim=1000  dis=1000\n",
            "[evt  384]  T5s= 7854  sim=1000  dis=1000\n",
            "[evt  385]  T5s= 7215  sim=1000  dis=1000\n",
            "[evt  386]  T5s= 6808  sim=1000  dis=1000\n",
            "[evt  387]  T5s= 9491  sim=1000  dis=1000\n",
            "[evt  388]  T5s= 6853  sim=1000  dis=1000\n",
            "[evt  389]  T5s= 5528  sim=1000  dis=1000\n",
            "[evt  390]  T5s= 7759  sim=1000  dis=1000\n",
            "[evt  391]  T5s= 7878  sim=1000  dis=1000\n",
            "[evt  392]  T5s= 9183  sim=1000  dis=1000\n",
            "[evt  393]  T5s= 5893  sim=1000  dis=1000\n",
            "[evt  394]  T5s= 7927  sim=1000  dis=1000\n",
            "[evt  395]  T5s= 9899  sim=1000  dis=1000\n",
            "[evt  396]  T5s= 6581  sim=1000  dis=1000\n",
            "[evt  397]  T5s= 7844  sim=1000  dis=1000\n",
            "[evt  398]  T5s= 5942  sim=1000  dis=1000\n",
            "[evt  399]  T5s= 7675  sim=1000  dis=1000\n",
            "[evt  400]  T5s= 7457  sim=1000  dis=1000\n",
            "[evt  401]  T5s= 5737  sim=1000  dis=1000\n",
            "[evt  402]  T5s= 6342  sim=1000  dis=1000\n",
            "[evt  403]  T5s= 6412  sim=1000  dis=1000\n",
            "[evt  404]  T5s= 7007  sim=1000  dis=1000\n",
            "[evt  405]  T5s= 6954  sim=1000  dis=1000\n",
            "[evt  406]  T5s= 9159  sim=1000  dis=1000\n",
            "[evt  407]  T5s= 7982  sim=1000  dis=1000\n",
            "[evt  408]  T5s= 7162  sim=1000  dis=1000\n",
            "[evt  409]  T5s= 7129  sim=1000  dis=1000\n",
            "[evt  410]  T5s= 6682  sim=1000  dis=1000\n",
            "[evt  411]  T5s= 6890  sim=1000  dis=1000\n",
            "[evt  412]  T5s= 6475  sim=1000  dis=1000\n",
            "[evt  413]  T5s= 6468  sim=1000  dis=1000\n",
            "[evt  414]  T5s=10506  sim=1000  dis=1000\n",
            "[evt  415]  T5s= 6573  sim=1000  dis=1000\n",
            "[evt  416]  T5s= 6418  sim=1000  dis=1000\n",
            "[evt  417]  T5s= 7179  sim=1000  dis=1000\n",
            "[evt  418]  T5s= 6045  sim=1000  dis=1000\n",
            "[evt  419]  T5s= 7358  sim=1000  dis=1000\n",
            "[evt  420]  T5s= 7902  sim=1000  dis=1000\n",
            "[evt  421]  T5s= 8645  sim=1000  dis=1000\n",
            "[evt  422]  T5s= 7391  sim=1000  dis=1000\n",
            "[evt  423]  T5s= 6921  sim=1000  dis=1000\n",
            "[evt  424]  T5s= 9305  sim=1000  dis=1000\n",
            "[evt  425]  T5s= 6073  sim=1000  dis=1000\n",
            "[evt  426]  T5s= 6706  sim=1000  dis=1000\n",
            "[evt  427]  T5s= 7211  sim=1000  dis=1000\n",
            "[evt  428]  T5s= 7649  sim=1000  dis=1000\n",
            "[evt  429]  T5s= 7309  sim=1000  dis=1000\n",
            "[evt  430]  T5s= 8768  sim=1000  dis=1000\n",
            "[evt  431]  T5s= 5992  sim=1000  dis=1000\n",
            "[evt  432]  T5s= 5130  sim=1000  dis=1000\n",
            "[evt  433]  T5s=10043  sim=1000  dis=1000\n",
            "[evt  434]  T5s= 7355  sim=1000  dis=1000\n",
            "[evt  435]  T5s= 7006  sim=1000  dis=1000\n",
            "[evt  436]  T5s= 6392  sim=1000  dis=1000\n",
            "[evt  437]  T5s= 8022  sim=1000  dis=1000\n",
            "[evt  438]  T5s= 7291  sim=1000  dis=1000\n",
            "[evt  439]  T5s= 8709  sim=1000  dis=1000\n",
            "[evt  440]  T5s= 6606  sim=1000  dis=1000\n",
            "[evt  441]  T5s= 7151  sim=1000  dis=1000\n",
            "[evt  442]  T5s= 8101  sim=1000  dis=1000\n",
            "[evt  443]  T5s= 7523  sim=1000  dis=1000\n",
            "[evt  444]  T5s= 8330  sim=1000  dis=1000\n",
            "[evt  445]  T5s= 7258  sim=1000  dis=1000\n",
            "[evt  446]  T5s= 6167  sim=1000  dis=1000\n",
            "[evt  447]  T5s= 5691  sim=1000  dis=1000\n",
            "[evt  448]  T5s= 7416  sim=1000  dis=1000\n",
            "[evt  449]  T5s= 8449  sim=1000  dis=1000\n",
            "[evt  450]  T5s= 6322  sim=1000  dis=1000\n",
            "[evt  451]  T5s= 7164  sim=1000  dis=1000\n",
            "[evt  452]  T5s= 6209  sim=1000  dis=1000\n",
            "[evt  453]  T5s= 6411  sim=1000  dis=1000\n",
            "[evt  454]  T5s= 7297  sim=1000  dis=1000\n",
            "[evt  455]  T5s= 7587  sim=1000  dis=1000\n",
            "[evt  456]  T5s= 6614  sim=1000  dis=1000\n",
            "[evt  457]  T5s= 5714  sim=1000  dis=1000\n",
            "[evt  458]  T5s= 6924  sim=1000  dis=1000\n",
            "[evt  459]  T5s= 7671  sim=1000  dis=1000\n",
            "[evt  460]  T5s= 6860  sim=1000  dis=1000\n",
            "[evt  461]  T5s= 7312  sim=1000  dis=1000\n",
            "[evt  462]  T5s= 7974  sim=1000  dis=1000\n",
            "[evt  463]  T5s= 7011  sim=1000  dis=1000\n",
            "[evt  464]  T5s= 7630  sim=1000  dis=1000\n",
            "[evt  465]  T5s= 8078  sim=1000  dis=1000\n",
            "[evt  466]  T5s= 6478  sim=1000  dis=1000\n",
            "[evt  467]  T5s= 6303  sim=1000  dis=1000\n",
            "[evt  468]  T5s= 5962  sim=1000  dis=1000\n",
            "[evt  469]  T5s=10333  sim=1000  dis=1000\n",
            "[evt  470]  T5s= 4648  sim=1000  dis=1000\n",
            "[evt  471]  T5s= 9176  sim=1000  dis=1000\n",
            "[evt  472]  T5s= 7290  sim=1000  dis=1000\n",
            "[evt  473]  T5s= 7459  sim=1000  dis=1000\n",
            "[evt  474]  T5s= 7572  sim=1000  dis=1000\n",
            "[evt  475]  T5s= 6568  sim=1000  dis=1000\n",
            "[evt  476]  T5s= 5133  sim=1000  dis=1000\n",
            "[evt  477]  T5s= 4910  sim=1000  dis=1000\n",
            "[evt  478]  T5s=10220  sim=1000  dis=1000\n",
            "[evt  479]  T5s= 5656  sim=1000  dis=1000\n",
            "[evt  480]  T5s= 5848  sim=1000  dis=1000\n",
            "[evt  481]  T5s= 8223  sim=1000  dis=1000\n",
            "[evt  482]  T5s= 9124  sim=1000  dis=1000\n",
            "[evt  483]  T5s= 7858  sim=1000  dis=1000\n",
            "[evt  484]  T5s= 5956  sim=1000  dis=1000\n",
            "[evt  485]  T5s= 5333  sim=1000  dis=1000\n",
            "[evt  486]  T5s=10120  sim=1000  dis=1000\n",
            "[evt  487]  T5s= 9291  sim=1000  dis=1000\n",
            "[evt  488]  T5s= 7591  sim=1000  dis=1000\n",
            "[evt  489]  T5s= 6944  sim=1000  dis=1000\n",
            "[evt  490]  T5s= 8157  sim=1000  dis=1000\n",
            "[evt  491]  T5s= 5324  sim=1000  dis=1000\n",
            "[evt  492]  T5s= 7980  sim=1000  dis=1000\n",
            "[evt  493]  T5s= 8475  sim=1000  dis=1000\n",
            "[evt  494]  T5s= 7953  sim=1000  dis=1000\n",
            "[evt  495]  T5s= 7727  sim=1000  dis=1000\n",
            "[evt  496]  T5s= 6411  sim=1000  dis=1000\n",
            "[evt  497]  T5s= 3851  sim=1000  dis=1000\n",
            "[evt  498]  T5s= 8969  sim=1000  dis=1000\n",
            "[evt  499]  T5s= 6232  sim=1000  dis=1000\n",
            "<<< done in 780.5s  | sim 500000  dis 500000  total 1000000\n",
            "17.86% of all pairs involve a displaced T5\n"
          ]
        }
      ],
      "source": [
        "import time, random, math, numpy as np\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DELTA_R2_CUT = 0.02\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "def _delta_phi(phi1, phi2):\n",
        "    \"\"\"same helper you already defined, but inline for the worker\"\"\"\n",
        "    d = phi1 - phi2\n",
        "    if d > math.pi:\n",
        "        d -= 2 * math.pi\n",
        "    elif d < -math.pi:\n",
        "        d += 2 * math.pi\n",
        "    return d\n",
        "# ---------------------------------------------------------------------------\n",
        "def _pairs_single_event(evt_idx,\n",
        "                        F, S, D,\n",
        "                        max_sim, max_dis,\n",
        "                        invalid_sim):\n",
        "    \"\"\"\n",
        "    Worker run in a separate process.\n",
        "    Returns two Python lists with the selected (i,j) indices per event.\n",
        "    \"\"\"\n",
        "    n = F.shape[0]\n",
        "    if n < 2:\n",
        "        return evt_idx, [], []\n",
        "\n",
        "    eta1 = F[:, 0] * eta_max\n",
        "    phi1 = np.arctan2(F[:, 2], F[:, 1])\n",
        "\n",
        "    # upper-triangle (non-diagonal) indices\n",
        "    idx_l, idx_r = np.triu_indices(n, k=1)\n",
        "    idxs_triu = np.stack((idx_l, idx_r), axis=-1)\n",
        "\n",
        "    # sim indices for each pair\n",
        "    simidx_l = S[idx_l]\n",
        "    simidx_r = S[idx_r]\n",
        "\n",
        "    # calculate DR2\n",
        "    eta_l = eta1[idx_l]\n",
        "    eta_r = eta1[idx_r]\n",
        "    phi_l = phi1[idx_l]\n",
        "    phi_r = phi1[idx_r]\n",
        "    dphi = np.abs(phi_l - phi_r)\n",
        "    dphi[dphi > np.pi] -= 2 * np.pi # adjust to [-pi, pi]\n",
        "    dr2 = (eta_l - eta_r)**2 + dphi**2\n",
        "\n",
        "    # make masks\n",
        "    dr2_valid = (dr2 < DELTA_R2_CUT)\n",
        "    sim_idx_same = (simidx_l == simidx_r)\n",
        "    sim_mask = dr2_valid & sim_idx_same & (simidx_l != invalid_sim)\n",
        "    dis_mask = dr2_valid & ~sim_idx_same\n",
        "\n",
        "    # get pairs from masks\n",
        "    sim_pairs = idxs_triu[sim_mask]\n",
        "    dis_pairs = idxs_triu[dis_mask]\n",
        "\n",
        "    # down-sample\n",
        "    random.seed(evt_idx)\n",
        "    if len(sim_pairs) > max_sim:\n",
        "        sim_pairs = sim_pairs[random.sample(range(len(sim_pairs)), max_sim)]\n",
        "    if len(dis_pairs) > max_dis:\n",
        "        dis_pairs = dis_pairs[random.sample(range(len(dis_pairs)), max_dis)]\n",
        "\n",
        "    print(f\"[evt {evt_idx:4d}]  T5s={n:5d}  sim={len(sim_pairs):3d}  dis={len(dis_pairs):3d}\")\n",
        "    return evt_idx, sim_pairs, dis_pairs\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "def create_t5_pairs_balanced_parallel(features_per_event,\n",
        "                                      sim_indices_per_event,\n",
        "                                      displaced_per_event,\n",
        "                                      *,\n",
        "                                      max_similar_pairs_per_event=100,\n",
        "                                      max_dissimilar_pairs_per_event=450,\n",
        "                                      invalid_sim_idx=-1,\n",
        "                                      n_workers=1):\n",
        "    t0 = time.time()\n",
        "    print(\"\\n>>> Pair generation  (ΔR² < 0.02)  –  parallel mode\")\n",
        "\n",
        "    work_args = [\n",
        "        (evt_idx,\n",
        "         features_per_event[evt_idx],\n",
        "         sim_indices_per_event[evt_idx],\n",
        "         displaced_per_event[evt_idx],\n",
        "         max_similar_pairs_per_event,\n",
        "         max_dissimilar_pairs_per_event,\n",
        "         invalid_sim_idx)\n",
        "        for evt_idx in range(len(features_per_event))\n",
        "    ]\n",
        "\n",
        "    sim_L, sim_R, sim_disp = [], [], []\n",
        "    dis_L, dis_R, dis_disp = [], [], []\n",
        "\n",
        "    with ProcessPoolExecutor(max_workers=1) as pool:\n",
        "        futures = [pool.submit(_pairs_single_event, *args) for args in work_args]\n",
        "        for fut in futures:\n",
        "            evt_idx, sim_pairs_evt, dis_pairs_evt = fut.result()\n",
        "            F = features_per_event[evt_idx]\n",
        "            D = displaced_per_event[evt_idx]\n",
        "\n",
        "            for i, j in sim_pairs_evt:\n",
        "                sim_L.append(F[i])\n",
        "                sim_R.append(F[j])\n",
        "                sim_disp.append(D[i] > 0.1 or D[j] > 0.1)\n",
        "\n",
        "            for i, j in dis_pairs_evt:\n",
        "                dis_L.append(F[i])\n",
        "                dis_R.append(F[j])\n",
        "                dis_disp.append(D[i] > 0.1 or D[j] > 0.1)\n",
        "\n",
        "    X_left  = np.concatenate([np.asarray(sim_L, dtype=np.float32),\n",
        "                              np.asarray(dis_L, dtype=np.float32)], axis=0)\n",
        "    X_right = np.concatenate([np.asarray(sim_R, dtype=np.float32),\n",
        "                              np.asarray(dis_R, dtype=np.float32)], axis=0)\n",
        "    y       = np.concatenate([np.zeros(len(sim_L), dtype=np.int32),\n",
        "                              np.ones (len(dis_L), dtype=np.int32)])\n",
        "\n",
        "    disp_L = np.concatenate([np.asarray(sim_disp, dtype=bool),\n",
        "                             np.asarray(dis_disp, dtype=bool)], axis=0)\n",
        "    disp_R = disp_L.copy()\n",
        "\n",
        "    print(f\"<<< done in {time.time() - t0:.1f}s  | sim {len(sim_L)}  dis {len(dis_L)}  total {len(y)}\")\n",
        "    return X_left, X_right, y, disp_L, disp_R\n",
        "\n",
        "# invoke\n",
        "X_left, X_right, y, disp_L, disp_R = create_t5_pairs_balanced_parallel(\n",
        "    features_per_event,\n",
        "    sim_indices_per_event,\n",
        "    displaced_per_event,\n",
        "    max_similar_pairs_per_event    = 1000,\n",
        "    max_dissimilar_pairs_per_event = 1000,\n",
        "    invalid_sim_idx                = -1,\n",
        "    n_workers                      = 1\n",
        ")\n",
        "\n",
        "if len(y) == 0:\n",
        "    raise ValueError(\"No pairs generated. Check filters/data.\")\n",
        "\n",
        "mask = (np.isfinite(X_left).all(axis=1) &\n",
        "        np.isfinite(X_right).all(axis=1))\n",
        "if not mask.all():\n",
        "    print(f\"Filtering {np.sum(~mask)} pairs with NaN/Inf\")\n",
        "    X_left, X_right, y, disp_L, disp_R = X_left[mask], X_right[mask], y[mask], disp_L[mask], disp_R[mask]\n",
        "\n",
        "weights_t5 = np.where(disp_L | disp_R, 5.0, 1.0).astype(np.float32)\n",
        "\n",
        "X_left_train, X_left_test, \\\n",
        "X_right_train, X_right_test, \\\n",
        "y_t5_train, y_t5_test, \\\n",
        "w_t5_train, w_t5_test = train_test_split(\n",
        "    X_left, X_right, y, weights_t5,\n",
        "    test_size=0.20, random_state=42,\n",
        "    stratify=y, shuffle=True\n",
        ")\n",
        "\n",
        "# compute displaced fraction\n",
        "pct_disp = np.mean(disp_L | disp_R) * 100\n",
        "print(f\"{pct_disp:.2f}% of all pairs involve a displaced T5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP7zBR8o7eXY",
        "outputId": "81da76b6-30e1-4dc0-dc37-9cf0937e1a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Building pLS-T5 pairs (ΔR² < 0.02) …\n",
            "[evt    0]  pLSs= 6936  T5s= 7083  sim=1000  dis=1000\n",
            "[evt    1]  pLSs= 6950  T5s= 6400  sim=1000  dis=1000\n",
            "[evt    2]  pLSs= 7200  T5s= 6708  sim=1000  dis=1000\n",
            "[evt    3]  pLSs= 7402  T5s= 7768  sim=1000  dis=1000\n",
            "[evt    4]  pLSs= 6129  T5s= 5870  sim=1000  dis=1000\n",
            "[evt    5]  pLSs= 7060  T5s= 7422  sim=1000  dis=1000\n",
            "[evt    6]  pLSs= 6758  T5s= 6374  sim=1000  dis=1000\n",
            "[evt    7]  pLSs= 8203  T5s= 9034  sim=1000  dis=1000\n",
            "[evt    8]  pLSs= 7525  T5s= 8741  sim=1000  dis=1000\n",
            "[evt    9]  pLSs= 8268  T5s= 7114  sim=1000  dis=1000\n",
            "[evt   10]  pLSs= 6677  T5s= 6965  sim=1000  dis=1000\n",
            "[evt   11]  pLSs= 6545  T5s= 6277  sim=1000  dis=1000\n",
            "[evt   12]  pLSs= 7499  T5s= 7587  sim=1000  dis=1000\n",
            "[evt   13]  pLSs= 8338  T5s= 8697  sim=1000  dis=1000\n",
            "[evt   14]  pLSs= 6602  T5s= 6359  sim=1000  dis=1000\n",
            "[evt   15]  pLSs= 7727  T5s= 8403  sim=1000  dis=1000\n",
            "[evt   16]  pLSs= 6422  T5s= 5981  sim=1000  dis=1000\n",
            "[evt   17]  pLSs= 5835  T5s= 5930  sim=1000  dis=1000\n",
            "[evt   18]  pLSs= 7731  T5s= 7760  sim=1000  dis=1000\n",
            "[evt   19]  pLSs= 8321  T5s= 7765  sim=1000  dis=1000\n",
            "[evt   20]  pLSs= 7585  T5s= 6925  sim=1000  dis=1000\n",
            "[evt   21]  pLSs= 7812  T5s= 7230  sim=1000  dis=1000\n",
            "[evt   22]  pLSs= 6252  T5s= 4984  sim=1000  dis=1000\n",
            "[evt   23]  pLSs= 7214  T5s= 7603  sim=1000  dis=1000\n",
            "[evt   24]  pLSs= 6938  T5s= 7119  sim=1000  dis=1000\n",
            "[evt   25]  pLSs=10081  T5s=10321  sim=1000  dis=1000\n",
            "[evt   26]  pLSs= 6421  T5s= 6796  sim=1000  dis=1000\n",
            "[evt   27]  pLSs= 7284  T5s= 6540  sim=1000  dis=1000\n",
            "[evt   28]  pLSs= 7576  T5s= 6947  sim=1000  dis=1000\n",
            "[evt   29]  pLSs= 6323  T5s= 5019  sim=1000  dis=1000\n",
            "[evt   30]  pLSs= 8873  T5s= 8798  sim=1000  dis=1000\n",
            "[evt   31]  pLSs= 7922  T5s= 7922  sim=1000  dis=1000\n",
            "[evt   32]  pLSs= 7763  T5s= 7620  sim=1000  dis=1000\n",
            "[evt   33]  pLSs= 7181  T5s= 7098  sim=1000  dis=1000\n",
            "[evt   34]  pLSs= 6972  T5s= 5685  sim=1000  dis=1000\n",
            "[evt   35]  pLSs= 7581  T5s= 6811  sim=1000  dis=1000\n",
            "[evt   36]  pLSs= 8027  T5s= 9102  sim=1000  dis=1000\n",
            "[evt   37]  pLSs= 7378  T5s= 7470  sim=1000  dis=1000\n",
            "[evt   38]  pLSs= 7287  T5s= 6897  sim=1000  dis=1000\n",
            "[evt   39]  pLSs= 8759  T5s= 8534  sim=1000  dis=1000\n",
            "[evt   40]  pLSs= 7516  T5s= 7615  sim=1000  dis=1000\n",
            "[evt   41]  pLSs= 7634  T5s= 6688  sim=1000  dis=1000\n",
            "[evt   42]  pLSs= 7831  T5s= 7705  sim=1000  dis=1000\n",
            "[evt   43]  pLSs= 7869  T5s= 7596  sim=1000  dis=1000\n",
            "[evt   44]  pLSs= 5176  T5s= 4815  sim=1000  dis=1000\n",
            "[evt   45]  pLSs= 7839  T5s= 7725  sim=1000  dis=1000\n",
            "[evt   46]  pLSs= 7024  T5s= 5784  sim=1000  dis=1000\n",
            "[evt   47]  pLSs= 7232  T5s= 6637  sim=1000  dis=1000\n",
            "[evt   48]  pLSs= 7070  T5s= 6918  sim=1000  dis=1000\n",
            "[evt   49]  pLSs= 9137  T5s= 9116  sim=1000  dis=1000\n",
            "[evt   50]  pLSs= 6124  T5s= 5916  sim=1000  dis=1000\n",
            "[evt   51]  pLSs= 8443  T5s= 7751  sim=1000  dis=1000\n",
            "[evt   52]  pLSs= 7977  T5s= 8330  sim=1000  dis=1000\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import time\n",
        "\n",
        "# pairing hyper-parameters\n",
        "DELTA_R2_CUT_PLS_T5 = 0.02\n",
        "DISP_VXY_CUT       = 0.1\n",
        "INVALID_SIM_IDX    = -1\n",
        "MAX_SIM            = 1000\n",
        "MAX_DIS            = 1000\n",
        "\n",
        "def _pairs_pLS_T5_single(evt_idx,\n",
        "                         F_pLS, S_pLS,\n",
        "                         F_T5,  S_T5, D_T5,\n",
        "                         max_sim, max_dis,\n",
        "                         invalid_sim):\n",
        "    \"\"\"\n",
        "    Build similar / dissimilar pLS-T5 pairs for a single event,\n",
        "    printing per-event summary.\n",
        "    \"\"\"\n",
        "    n_p, n_t = F_pLS.shape[0], F_T5.shape[0]\n",
        "    sim_pairs, dis_pairs = [], []\n",
        "\n",
        "    # if either collection is empty, report zeros and bail\n",
        "    if n_p == 0 or n_t == 0:\n",
        "        print(f\"[evt {evt_idx:4d}]  pLSs={n_p:5d}  T5s={n_t:5d}  sim={0:4d}  dis={0:4d}\")\n",
        "        return evt_idx, []\n",
        "\n",
        "    # un-normalize eta and compute phi angles\n",
        "    eta_p = F_pLS[:,0] * 4.0\n",
        "    phi_p = np.arctan2(F_pLS[:,3], F_pLS[:,2])\n",
        "    eta_t = F_T5[:,0] * eta_max\n",
        "    phi_t = np.arctan2(F_T5[:,2], F_T5[:,1])\n",
        "\n",
        "    # make all possible pairs (i, j)\n",
        "    idx_p, idx_t = np.indices( (n_p, n_t) )\n",
        "    idx_p, idx_t = idx_p.flatten(), idx_t.flatten()\n",
        "\n",
        "    # calculate angles\n",
        "    dphi = (phi_p[idx_p] - phi_t[idx_t] + np.pi) % (2 * np.pi) - np.pi\n",
        "    dr2 = (eta_p[idx_p] - eta_t[idx_t])**2 + dphi**2\n",
        "    dr2_valid = (dr2 < DELTA_R2_CUT_PLS_T5)\n",
        "\n",
        "    # compare sim indices\n",
        "    simidx_p = S_pLS[idx_p]\n",
        "    simidx_t = S_T5[idx_t]\n",
        "    sim_idx_same = (simidx_p == simidx_t)\n",
        "\n",
        "    # create masks for similar and dissimilar pairs\n",
        "    sim_mask = dr2_valid & sim_idx_same & (simidx_p != invalid_sim)\n",
        "    dis_mask = dr2_valid & ~sim_idx_same\n",
        "\n",
        "    # get the pairs\n",
        "    sim_pairs = np.column_stack((idx_p[sim_mask], idx_t[sim_mask]))\n",
        "    dis_pairs = np.column_stack((idx_p[dis_mask], idx_t[dis_mask]))\n",
        "\n",
        "    # down-sample\n",
        "    random.seed(evt_idx)\n",
        "    if len(sim_pairs) > max_sim:\n",
        "        sim_pairs = sim_pairs[random.sample(range(len(sim_pairs)), max_sim)]\n",
        "    if len(dis_pairs) > max_dis:\n",
        "        dis_pairs = dis_pairs[random.sample(range(len(dis_pairs)), max_dis)]\n",
        "\n",
        "    # print per-event summary\n",
        "    print(f\"[evt {evt_idx:4d}]  pLSs={n_p:5d}  T5s={n_t:5d}  \"\n",
        "          f\"sim={len(sim_pairs):4d}  dis={len(dis_pairs):4d}\")\n",
        "\n",
        "    # pack into (feature, feature, label, displaced_flag)\n",
        "    packed = []\n",
        "    for i,j in sim_pairs:\n",
        "        packed.append((F_pLS[i], F_T5[j], 0, D_T5[j] > DISP_VXY_CUT))\n",
        "    for i,j in dis_pairs:\n",
        "        packed.append((F_pLS[i], F_T5[j], 1, D_T5[j] > DISP_VXY_CUT))\n",
        "\n",
        "    return evt_idx, packed\n",
        "\n",
        "# now drive over all events in parallel, with a global timer & totals\n",
        "print(f\"\\n>>> Building pLS-T5 pairs (ΔR² < {DELTA_R2_CUT_PLS_T5}) …\")\n",
        "t0 = time.time()\n",
        "all_packed = []\n",
        "sim_total = 0\n",
        "dis_total = 0\n",
        "\n",
        "with ProcessPoolExecutor(max_workers=1) as pool:\n",
        "    futures = [\n",
        "        pool.submit(\n",
        "            _pairs_pLS_T5_single, ev,\n",
        "            pLS_features_per_event[ev],\n",
        "            pLS_sim_indices_per_event[ev],\n",
        "            features_per_event[ev],\n",
        "            sim_indices_per_event[ev],\n",
        "            displaced_per_event[ev],\n",
        "            MAX_SIM, MAX_DIS, INVALID_SIM_IDX\n",
        "        )\n",
        "        for ev in range(len(features_per_event))\n",
        "    ]\n",
        "    for fut in futures:\n",
        "        _, packed = fut.result()\n",
        "        # accumulate\n",
        "        sim_evt = sum(1 for _,_,lbl,_ in packed if lbl == 0)\n",
        "        dis_evt = sum(1 for _,_,lbl,_ in packed if lbl == 1)\n",
        "        sim_total += sim_evt\n",
        "        dis_total += dis_evt\n",
        "        all_packed.extend(packed)\n",
        "\n",
        "print(f\"<<< done in {time.time() - t0:.1f}s  \"\n",
        "      f\"| sim {sim_total:5d}  dis {dis_total:5d}  total {len(all_packed):,d}\")\n",
        "\n",
        "# unpack into numpy arrays\n",
        "pls_feats = np.array([p[0] for p in all_packed], dtype=np.float32)\n",
        "t5_feats  = np.array([p[1] for p in all_packed], dtype=np.float32)\n",
        "y_pls     = np.array([p[2] for p in all_packed], dtype=np.int32)\n",
        "disp_flag = np.array([p[3] for p in all_packed], dtype=bool)\n",
        "w_pls     = np.array([5.0 if p[3] else 1.0 for p in all_packed], dtype=np.float32)\n",
        "\n",
        "# train/test split\n",
        "X_pls_train, X_pls_test, \\\n",
        "X_t5raw_train, X_t5raw_test, \\\n",
        "y_pls_train, y_pls_test, \\\n",
        "w_pls_train, w_pls_test = train_test_split(\n",
        "    pls_feats, t5_feats, y_pls, w_pls,\n",
        "    test_size=0.20, random_state=42,\n",
        "    stratify=y_pls, shuffle=True\n",
        ")\n",
        "\n",
        "pct_disp_pls = disp_flag.mean() * 100.0\n",
        "print(f\"pLS-T5 pairs → train {len(y_pls_train)}  test {len(y_pls_test)}\")\n",
        "print(f\"{pct_disp_pls:.2f}% of pLS-T5 pairs involve a displaced T5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRjYLeU67eXY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SiameseDataset(Dataset):\n",
        "    def __init__(self, X_left, X_right, y, w):\n",
        "        if not isinstance(X_left, np.ndarray):  X_left  = np.array(X_left)\n",
        "        if not isinstance(X_right, np.ndarray): X_right = np.array(X_right)\n",
        "        if not isinstance(y, np.ndarray):       y       = np.array(y)\n",
        "        if not isinstance(w, np.ndarray):       w       = np.array(w)\n",
        "        self.X_left  = torch.from_numpy(X_left .astype(np.float32))\n",
        "        self.X_right = torch.from_numpy(X_right.astype(np.float32))\n",
        "        self.y       = torch.from_numpy(y      .astype(np.float32)).view(-1,1)\n",
        "        self.w       = torch.from_numpy(w      .astype(np.float32)).view(-1,1)\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X_left[idx], self.X_right[idx], self.y[idx], self.w[idx]\n",
        "\n",
        "train_t5_ds = SiameseDataset(X_left_train, X_right_train, y_t5_train, w_t5_train)\n",
        "test_t5_ds  = SiameseDataset(X_left_test,  X_right_test,  y_t5_test,  w_t5_test)\n",
        "\n",
        "# new Dataset for pLS-T5 raw‐feature pairs\n",
        "class PLST5Dataset(Dataset):\n",
        "    def __init__(self, pls, t5, y, w):\n",
        "        self.pls = torch.from_numpy(pls)\n",
        "        self.t5  = torch.from_numpy(t5)\n",
        "        self.y   = torch.from_numpy(y.reshape(-1,1).astype(np.float32))\n",
        "        self.w   = torch.from_numpy(w.reshape(-1,1).astype(np.float32))\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, i):\n",
        "        return self.pls[i], self.t5[i], self.y[i], self.w[i]\n",
        "\n",
        "train_pls_ds = PLST5Dataset(X_pls_train, X_t5raw_train, y_pls_train, w_pls_train)\n",
        "test_pls_ds  = PLST5Dataset(X_pls_test,  X_t5raw_test,  y_pls_test,  w_pls_test)\n",
        "\n",
        "batch_size = 1024\n",
        "num_workers = min(os.cpu_count() or 4, 8)\n",
        "\n",
        "train_t5_loader = DataLoader(train_t5_ds, batch_size, shuffle=True,\n",
        "                             num_workers=num_workers, pin_memory=True)\n",
        "test_t5_loader  = DataLoader(test_t5_ds,  batch_size, shuffle=False,\n",
        "                             num_workers=num_workers, pin_memory=True)\n",
        "train_pls_loader = DataLoader(train_pls_ds, batch_size, shuffle=True,\n",
        "                              num_workers=num_workers, pin_memory=True)\n",
        "test_pls_loader  = DataLoader(test_pls_ds,  batch_size, shuffle=False,\n",
        "                              num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "print(\"Loaders ready:\",\n",
        "      f\"T5 train {len(train_t5_ds)}, pLS-T5 train {len(train_pls_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO-XMaqh7eXY"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# T5 embedding net (same as before)\n",
        "class EmbeddingNetT5(nn.Module):\n",
        "    def __init__(self, input_dim=30, emb_dim=6):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 32); self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, 32);         self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(32, emb_dim)\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.fc1(x))\n",
        "        x = self.relu2(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "# pLS embedding net\n",
        "class EmbeddingNetpLS(nn.Module):\n",
        "    def __init__(self, input_dim=10, emb_dim=6):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 32); self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, 32);         self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(32, emb_dim)\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.fc1(x))\n",
        "        x = self.relu2(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "# T5 embedding net (same as before)\n",
        "class CosEmbeddingNetT5(nn.Module):\n",
        "    def __init__(self, input_dim=30, emb_dim=6):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 32); self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, 32);         self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(32, emb_dim)\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.fc1(x))\n",
        "        x = self.relu2(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "# pLS embedding net\n",
        "class CosEmbeddingNetpLS(nn.Module):\n",
        "    def __init__(self, input_dim=10, emb_dim=6):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 32); self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, 32);         self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(32, emb_dim)\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.fc1(x))\n",
        "        x = self.relu2(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "    def forward(self, d, label, weight=None):\n",
        "        # d: [B,1], label: [B,1], weight: [B,1] or None\n",
        "        l_sim = (1 - label) * d.pow(2)\n",
        "        l_dis = label * (self.margin - d).clamp(min=0.0).pow(2)\n",
        "        loss = l_sim + l_dis\n",
        "        if weight is not None:\n",
        "            loss = loss * weight\n",
        "        return loss.mean()\n",
        "\n",
        "class CosineContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "    def forward(self, d, label, weight=None):\n",
        "        # d: [B,1], label: [B,1], weight: [B,1] or None\n",
        "        l_sim = (1 - label) * d.pow(2)\n",
        "        l_dis = label * (self.margin - d).clamp(min=0.0).pow(2)\n",
        "        loss = l_sim + l_dis\n",
        "        if weight is not None:\n",
        "            loss = loss * weight\n",
        "        return loss.mean()\n",
        "\n",
        "# contrastive loss (reuse)\n",
        "criterion = ContrastiveLoss(margin=1.0)\n",
        "coscriterion = CosineContrasiveLoss(margin = 1.0)\n",
        "\n",
        "\n",
        "# instantiate and send to GPU/CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "embed_t5 = EmbeddingNetT5().to(device)\n",
        "embed_pls = EmbeddingNetpLS().to(device)\n",
        "cembed_t5 = CosEmbeddingNetT5().to(device)\n",
        "cembed_pls = CosEmbeddingNetpLS().to(device)\n",
        "\n",
        "# joint optimizer over both nets\n",
        "optimizer = optim.Adam(\n",
        "    list(embed_t5.parameters()) + list(embed_pls.parameters()),\n",
        "    lr=0.0025\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rae7KGyP7eXY"
      },
      "outputs": [],
      "source": [
        "num_epochs = 200\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    embed_t5.train(); embed_pls.train()\n",
        "    total_loss = 0.0\n",
        "    total_t5   = 0.0\n",
        "    total_pls  = 0.0\n",
        "\n",
        "    # zip will stop at the shorter loader; you can also use itertools.cycle if needed\n",
        "    for (l, r, y0, w0), (p5, t5f, y1, w1) in zip(train_t5_loader, train_pls_loader):\n",
        "        # to device\n",
        "        l   = l.to(device);   r    = r.to(device)\n",
        "        y0_ = y0.to(device);  w0_  = w0.to(device)\n",
        "        p5  = p5.to(device);  t5f_ = t5f.to(device)\n",
        "        y1_ = y1.to(device);  w1_  = w1.to(device)\n",
        "\n",
        "        # --- T5–T5 forward & loss ---\n",
        "        e_l = embed_t5(l);  e_r = embed_t5(r)\n",
        "        d0 = torch.sqrt(((e_l-e_r)**2).sum(1,keepdim=True) + 1e-6)\n",
        "        loss0 = criterion(d0, y0_, w0_)\n",
        "\n",
        "        # --- pLS-T5 forward & loss ---\n",
        "        e_p5 = embed_pls(p5)\n",
        "        e_t5 = embed_t5(t5f_)\n",
        "        d1 = torch.sqrt(((e_p5-e_t5)**2).sum(1,keepdim=True) + 1e-6)\n",
        "        loss1 = criterion(d1, y1_, w1_)\n",
        "\n",
        "        loss = loss0 + loss1\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_t5  += loss0.item()\n",
        "        total_pls += loss1.item()\n",
        "\n",
        "    avg_loss   = total_loss / len(train_pls_loader)\n",
        "    avg_t5     = total_t5   / len(train_t5_loader)\n",
        "    avg_pls    = total_pls  / len(train_pls_loader)\n",
        "    print(f\"Epoch {epoch}/{num_epochs}:  JointLoss={avg_loss:.4f}  \"\n",
        "          f\"T5={avg_t5:.4f}  pLS={avg_pls:.4f}\")\n",
        "\n",
        "# --- Setup for Cosine Model ---\n",
        "coptimizer = optim.Adam(\n",
        "    list(cembed_t5.parameters()) + list(cembed_pls.parameters()),\n",
        "    lr=0.0025\n",
        ")\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    cembed_t5.train(); cembed_pls.train()\n",
        "    ctotal_loss = 0.0\n",
        "\n",
        "    for (l, r, y0, w0), (p5, t5f, y1, w1) in zip(train_t5_loader, train_pls_loader):\n",
        "        l, r, y0_, w0_ = l.to(device), r.to(device), y0.to(device), w0.to(device)\n",
        "        p5, t5f_, y1_, w1_ = p5.to(device), t5f.to(device), y1.to(device), w1.to(device)\n",
        "\n",
        "        # --- T5–T5 Cosine Distance ---\n",
        "        e_l, e_r = cembed_t5(l), cembed_t5(r)\n",
        "        # Cosine distance = 1 - similarity\n",
        "        d0 = 1.0 - torch.nn.functional.cosine_similarity(e_l, e_r, dim=1, eps=1e-8).view(-1, 1)\n",
        "        loss0 = coscriterion(d0, y0_, w0_)\n",
        "\n",
        "        # --- pLS-T5 Cosine Distance ---\n",
        "        e_p5 = cembed_pls(p5)\n",
        "        e_t5 = cembed_t5(t5f_)\n",
        "        d1 = 1.0 - torch.nn.functional.cosine_similarity(e_p5, e_t5, dim=1, eps=1e-8).view(-1, 1)\n",
        "        loss1 = coscriterion(d1, y1_, w1_)\n",
        "\n",
        "        loss = loss0 + loss1\n",
        "        coptimizer.zero_grad() # Use coptimizer here!\n",
        "        loss.backward()\n",
        "        coptimizer.step()\n",
        "        ctotal_loss += loss.item()\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Cosine Epoch {epoch}: Loss={ctotal_loss/len(train_pls_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zyZ5skF7eXZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "embed_t5.eval()\n",
        "\n",
        "# 1) collect distances and labels\n",
        "dist_t5_all = []\n",
        "lbl_t5_all  = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_left, x_right, y, _ in test_t5_loader:\n",
        "        x_left  = x_left.to(device)\n",
        "        x_right = x_right.to(device)\n",
        "\n",
        "        e_l = embed_t5(x_left)\n",
        "        e_r = embed_t5(x_right)\n",
        "        d   = torch.sqrt(((e_l - e_r) ** 2).sum(dim=1, keepdim=True) + 1e-6)\n",
        "\n",
        "        dist_t5_all.append(d.cpu().numpy().flatten())\n",
        "        lbl_t5_all .append(y.numpy().flatten())\n",
        "\n",
        "dist_t5_all = np.concatenate(dist_t5_all)\n",
        "lbl_t5_all  = np.concatenate(lbl_t5_all)\n",
        "\n",
        "print(f\"T5-T5 pairs:   {len(dist_t5_all)} distances\")\n",
        "print(f\"  Range: min={dist_t5_all.min():.4f}, max={dist_t5_all.max():.4f}\")\n",
        "print(f\"  Labels: similar={(lbl_t5_all==0).sum()}, dissimilar={(lbl_t5_all==1).sum()}\")\n",
        "\n",
        "# 2) histogram of distances\n",
        "plt.figure(figsize=(10,6))\n",
        "bins = np.linspace(0, 7.5, 100)\n",
        "plt.hist(dist_t5_all[lbl_t5_all==0], bins=bins, density=True, alpha=0.6, label='Duplicates (0)')\n",
        "plt.hist(dist_t5_all[lbl_t5_all==1], bins=bins, density=True, alpha=0.6, label='Non-Duplicates (1)')\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"Euclidean Distance\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.title(\"T5-T5 Embedding Distance Distribution (Test Set)\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.xlim(0,7.5)\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# ΔR² baseline for the same test split\n",
        "# ------------------------------------------------------------------\n",
        "phi_left  = np.arctan2(X_left_test[:, 2], X_left_test[:, 1])\n",
        "phi_right = np.arctan2(X_right_test[:, 2], X_right_test[:, 1])\n",
        "eta_left  = X_left_test[:, 0]  * eta_max     # undo η‑normalisation\n",
        "eta_right = X_right_test[:, 0] * eta_max\n",
        "\n",
        "dphi = (phi_left - phi_right + np.pi) % (2*np.pi) - np.pi\n",
        "deta = eta_left - eta_right\n",
        "dRsq = dphi**2 + deta**2\n",
        "\n",
        "# 3) ROC curves: embedding vs ΔR² baseline\n",
        "fpr_t5, tpr_t5, _ = roc_curve(lbl_t5_all, -dist_t5_all, pos_label=0)\n",
        "fpr_dr, tpr_dr, _ = roc_curve(lbl_t5_all, -dRsq,        pos_label=0)\n",
        "\n",
        "auc_t5 = auc(fpr_t5, tpr_t5)\n",
        "auc_dr = auc(fpr_dr,  tpr_dr)\n",
        "\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.plot(fpr_t5, tpr_t5, label=f\"Embedding distance (AUC={auc_t5:.3f})\")\n",
        "plt.plot(fpr_dr, tpr_dr, '--', label=f\"ΔR² baseline (AUC={auc_dr:.3f})\")\n",
        "plt.plot([0,1],[0,1], '--', color='grey')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"T5-T5 Duplicate Discrimination\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"T5-T5 AUC (embedding) = {auc_t5:.4f}\")\n",
        "print(f\"T5-T5 AUC (ΔR²)       = {auc_dr :.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9_Jrf8Fp-bz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "embed_t5.eval()\n",
        "cembed_t5.eval()\n",
        "\n",
        "dist_euc_all = []\n",
        "dist_cos_all = []\n",
        "lbl_t5_all  = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_left, x_right, y, _ in test_t5_loader:\n",
        "        x_left, x_right = x_left.to(device), x_right.to(device)\n",
        "\n",
        "        # 1) Euclidean Model Scores\n",
        "        e_l_e, e_r_e = embed_t5(x_left), embed_t5(x_right)\n",
        "        d_euc = torch.sqrt(((e_l_e - e_r_e) ** 2).sum(dim=1, keepdim=True) + 1e-6)\n",
        "        dist_euc_all.append(d_euc.cpu().numpy().flatten())\n",
        "\n",
        "        # 2) Cosine Model Scores\n",
        "        e_l_c, e_r_c = cembed_t5(x_left), cembed_t5(x_right)\n",
        "        d_cos = 1.0 - F.cosine_similarity(e_l_c, e_r_c, dim=1).view(-1, 1)\n",
        "        dist_cos_all.append(d_cos.cpu().numpy().flatten())\n",
        "\n",
        "        lbl_t5_all.append(y.numpy().flatten())\n",
        "\n",
        "dist_euc_all = np.concatenate(dist_euc_all)\n",
        "dist_cos_all = np.concatenate(dist_cos_all)\n",
        "lbl_t5_all  = np.concatenate(lbl_t5_all)\n",
        "\n",
        "# --- Compute ROC curves ---\n",
        "# (pos_label=0 because your label 0 = duplicate, and ROC usually expects\n",
        "# smaller distances for positives, hence the negative sign)\n",
        "fpr_euc, tpr_euc, _ = roc_curve(lbl_t5_all, -dist_euc_all, pos_label=0)\n",
        "fpr_cos, tpr_cos, _ = roc_curve(lbl_t5_all, -dist_cos_all, pos_label=0)\n",
        "\n",
        "# ΔR² Baseline\n",
        "phi_left, phi_right = np.arctan2(X_left_test[:, 2], X_left_test[:, 1]), np.arctan2(X_right_test[:, 2], X_right_test[:, 1])\n",
        "eta_left, eta_right = X_left_test[:, 0] * 2.5, X_right_test[:, 0] * 2.5 # assuming eta_max=2.5\n",
        "dRsq = ((phi_left - phi_right + np.pi) % (2*np.pi) - np.pi)**2 + (eta_left - eta_right)**2\n",
        "fpr_dr, tpr_dr, _ = roc_curve(lbl_t5_all, -dRsq, pos_label=0)\n",
        "\n",
        "# --- Plot Combined ROC ---\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(fpr_euc, tpr_euc, label=f\"Euclidean Embedding (AUC={auc(fpr_euc, tpr_euc):.3f})\", color='blue')\n",
        "plt.plot(fpr_cos, tpr_cos, label=f\"Cosine Embedding (AUC={auc(fpr_cos, tpr_cos):.3f})\", color='red')\n",
        "plt.plot(fpr_dr, tpr_dr, '--', label=f\"ΔR² baseline (AUC={auc(fpr_dr, tpr_dr):.3f})\", color='green')\n",
        "plt.plot([0,1],[0,1], '--', color='grey')\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"T5-T5 Duplicate Discrimination: Metric Comparison\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHDl5cQQ7eXZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "embed_pls.eval(); embed_t5.eval()\n",
        "\n",
        "# 1) collect distances and labels ------------------------------------\n",
        "dist_pls_all = []\n",
        "lbl_pls_all  = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for pls_feats, t5_feats, y, _ in test_pls_loader:\n",
        "        pls_feats = pls_feats.to(device)\n",
        "        t5_feats  = t5_feats.to(device)\n",
        "\n",
        "        e_p = embed_pls(pls_feats)\n",
        "        e_t = embed_t5(t5_feats)\n",
        "        d   = torch.sqrt(((e_p - e_t) ** 2).sum(dim=1, keepdim=True) + 1e-6)\n",
        "\n",
        "        dist_pls_all.append(d.cpu().numpy().flatten())\n",
        "        lbl_pls_all .append(y.numpy().flatten())\n",
        "\n",
        "dist_pls_all = np.concatenate(dist_pls_all)\n",
        "lbl_pls_all  = np.concatenate(lbl_pls_all)\n",
        "\n",
        "print(f\"pLS-T5 pairs:  {len(dist_pls_all)} distances\")\n",
        "print(f\"  Range: min={dist_pls_all.min():.4f}, max={dist_pls_all.max():.4f}\")\n",
        "print(f\"  Labels: similar={(lbl_pls_all==0).sum()}, dissimilar={(lbl_pls_all==1).sum()}\")\n",
        "\n",
        "# 2) histogram of distances ------------------------------------------\n",
        "plt.figure(figsize=(10,6))\n",
        "bins = np.linspace(0, dist_pls_all.max(), 100)\n",
        "plt.hist(dist_pls_all[lbl_pls_all==0], bins=bins, density=True, alpha=0.6, label='Duplicates (0)')\n",
        "plt.hist(dist_pls_all[lbl_pls_all==1], bins=bins, density=True, alpha=0.6, label='Non-Duplicates (1)')\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"Euclidean Distance\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.title(\"pLS-T5 Embedding Distance Distribution (Test Set)\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.xlim(left=0)\n",
        "plt.show()\n",
        "\n",
        "# --------------------------------------------------------------------\n",
        "# ΔR² baseline for the same pLS-T5 pairs\n",
        "# --------------------------------------------------------------------\n",
        "#  — recover φ and η for the raw feature arrays used in the split\n",
        "phi_left  = np.arctan2(X_pls_test[:, 3],  X_pls_test[:, 2])     # pLS: sinφ, cosφ\n",
        "phi_right = np.arctan2(X_t5raw_test[:, 2], X_t5raw_test[:, 1])  # T5 : sinφ, cosφ\n",
        "eta_left  = X_pls_test[:, 0]  * 4.0        # pLS stored η/4\n",
        "eta_right = X_t5raw_test[:, 0] * eta_max   # T5  stored η/η_max\n",
        "\n",
        "dphi = (phi_left - phi_right + np.pi) % (2*np.pi) - np.pi\n",
        "deta = eta_left - eta_right\n",
        "dRsq = dphi**2 + deta**2\n",
        "\n",
        "# 3) ROC curves: embedding vs ΔR² baseline ---------------------------\n",
        "fpr_pls, tpr_pls, _ = roc_curve(lbl_pls_all, -dist_pls_all, pos_label=0)\n",
        "fpr_dr,  tpr_dr,  _ = roc_curve(lbl_pls_all, -dRsq,         pos_label=0)\n",
        "\n",
        "auc_pls = auc(fpr_pls, tpr_pls)\n",
        "auc_dr  = auc(fpr_dr,  tpr_dr)\n",
        "\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.plot(fpr_pls, tpr_pls, label=f\"Embedding distance (AUC={auc_pls:.3f})\")\n",
        "plt.plot(fpr_dr,  tpr_dr,  '--', label=f\"ΔR² baseline (AUC={auc_dr:.3f})\")\n",
        "plt.plot([0,1],[0,1], '--', color='grey')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"pLS-T5 Duplicate Discrimination\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"pLS-T5 AUC (embedding) = {auc_pls:.4f}\")\n",
        "print(f\"pLS-T5 AUC (ΔR²)       = {auc_dr :.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL_yVcUf7eXZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np, torch, matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "percentiles   = [80, 85, 90, 93, 95, 98, 99]   # keep this % of non‑duplicates\n",
        "eta_edges     = np.arange(0.0, 2.75, 0.25)     # |η| binning\n",
        "dr2_threshold = 1.0e-3                         # ΔR² cut\n",
        "\n",
        "eta_L  = X_left_test[:, 0] * eta_max\n",
        "phi_L  = np.arctan2(X_left_test[:, 2], X_left_test[:, 1])\n",
        "eta_R  = X_right_test[:, 0] * eta_max\n",
        "phi_R  = np.arctan2(X_right_test[:, 2], X_right_test[:, 1])\n",
        "\n",
        "abs_eta = np.abs(eta_L)\n",
        "\n",
        "deta = eta_L - eta_R\n",
        "dphi = (phi_R - phi_L + np.pi) % (2*np.pi) - np.pi\n",
        "dR2  = deta**2 + dphi**2                       # ΔR² baseline\n",
        "\n",
        "embed_t5.eval()\n",
        "with torch.no_grad():\n",
        "    L = torch.from_numpy(X_left_test.astype(np.float32)).to(device)\n",
        "    R = torch.from_numpy(X_right_test.astype(np.float32)).to(device)\n",
        "    dist = torch.sqrt(((embed_t5(L) - embed_t5(R))**2).sum(dim=1) + 1e-6) \\\n",
        "             .cpu().numpy()\n",
        "\n",
        "y_test = y_t5_test                              # shorthand\n",
        "\n",
        "cut_vals   = {p: [] for p in percentiles}\n",
        "dup_rej    = {p: [] for p in percentiles}\n",
        "dr2_eff    = []\n",
        "dr2_rejdup = []\n",
        "\n",
        "for lo, hi in zip(eta_edges[:-1], eta_edges[1:]):\n",
        "    nnd = (abs_eta >= lo) & (abs_eta < hi) & (y_test == 1)   # non‑dups\n",
        "    dup = (abs_eta >= lo) & (abs_eta < hi) & (y_test == 0)   # dups\n",
        "\n",
        "    # ΔR² metrics\n",
        "    dr2_eff   .append(np.mean(dR2[nnd] >= dr2_threshold)*100 if np.any(nnd) else np.nan)\n",
        "    dr2_rejdup.append(np.mean(dR2[dup] <  dr2_threshold)*100 if np.any(dup) else np.nan)\n",
        "\n",
        "    # embedding‑distance cuts\n",
        "    for p in percentiles:\n",
        "        cut = np.percentile(dist[nnd], 100-p) if np.any(nnd) else np.nan\n",
        "        cut_vals[p].append(cut)\n",
        "        dup_rej[p].append(np.mean(dist[dup] < cut)*100 if (np.any(dup) and not np.isnan(cut)) else np.nan)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "h = ax.hist2d(abs_eta[y_test==1], dist[y_test==1],\n",
        "              bins=[eta_edges, 50], norm=LogNorm())\n",
        "fig.colorbar(h[3], ax=ax, label='Counts')\n",
        "ax.set_xlabel('|η| (hit 0)')\n",
        "ax.set_ylabel('Embedding distance')\n",
        "ax.set_title('T5-T5  •  Embedding distance vs |η|  (test non‑duplicates)')\n",
        "\n",
        "mid_eta = eta_edges[:-1] + 0.5*np.diff(eta_edges)\n",
        "for p, clr in zip(percentiles, plt.cm.rainbow(np.linspace(0,1,len(percentiles)))):\n",
        "    ax.plot(mid_eta, cut_vals[p], '-o', color=clr, label=f'{p}% retention')\n",
        "ax.legend(); ax.grid(alpha=0.3); plt.show()\n",
        "\n",
        "for p in percentiles:\n",
        "    cuts = \", \".join(f\"{v:.4f}\" if not np.isnan(v) else \"nan\" for v in cut_vals[p])\n",
        "    rejs = \", \".join(f\"{v:.2f}\"  if not np.isnan(v) else \"nan\" for v in dup_rej[p])\n",
        "    print(f\"{p}%-cut:     {{ {cuts} }}\")\n",
        "    print(f\"  {p}%-dupRej: {{ {rejs} }}\")\n",
        "    print()\n",
        "eff = \", \".join(f\"{v:.2f}\" if not np.isnan(v) else \"nan\" for v in dr2_eff)\n",
        "rej = \", \".join(f\"{v:.2f}\" if not np.isnan(v) else \"nan\" for v in dr2_rejdup)\n",
        "print(f\"dR2-eff  (%): {{ {eff} }}\")\n",
        "print(f\"dR2-dupRej (%): {{ {rej} }}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7JQHQpW7eXZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np, torch, matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "percentiles   = [80, 85, 90, 93, 95, 98, 99]\n",
        "eta_edges     = np.arange(0.0, 2.75, 0.25)\n",
        "dr2_threshold = 1.0e-3\n",
        "\n",
        "eta_L  = X_pls_test[:, 0] * 4.0                     # pLS η was stored as η/4\n",
        "phi_L  = np.arctan2(X_pls_test[:, 3], X_pls_test[:, 2])\n",
        "eta_R  = X_t5raw_test[:, 0] * eta_max\n",
        "phi_R  = np.arctan2(X_t5raw_test[:, 2], X_t5raw_test[:, 1])\n",
        "\n",
        "abs_eta = np.abs(eta_L)\n",
        "\n",
        "deta = eta_L - eta_R\n",
        "dphi = (phi_R - phi_L + np.pi) % (2*np.pi) - np.pi\n",
        "dR2  = deta**2 + dphi**2\n",
        "\n",
        "embed_pls.eval(); embed_t5.eval()\n",
        "with torch.no_grad():\n",
        "    L = torch.from_numpy(X_pls_test.astype(np.float32)).to(device)\n",
        "    R = torch.from_numpy(X_t5raw_test.astype(np.float32)).to(device)\n",
        "    dist = torch.sqrt(((embed_pls(L) - embed_t5(R))**2).sum(dim=1) + 1e-6) \\\n",
        "             .cpu().numpy()\n",
        "\n",
        "y_test = y_pls_test\n",
        "\n",
        "cut_vals   = {p: [] for p in percentiles}\n",
        "dup_rej    = {p: [] for p in percentiles}\n",
        "dr2_eff    = []\n",
        "dr2_rejdup = []\n",
        "\n",
        "for lo, hi in zip(eta_edges[:-1], eta_edges[1:]):\n",
        "    nnd = (abs_eta >= lo) & (abs_eta < hi) & (y_test == 1)\n",
        "    dup = (abs_eta >= lo) & (abs_eta < hi) & (y_test == 0)\n",
        "\n",
        "    dr2_eff   .append(np.mean(dR2[nnd] >= dr2_threshold)*100 if np.any(nnd) else np.nan)\n",
        "    dr2_rejdup.append(np.mean(dR2[dup] <  dr2_threshold)*100 if np.any(dup) else np.nan)\n",
        "\n",
        "    for p in percentiles:\n",
        "        cut = np.percentile(dist[nnd], 100-p) if np.any(nnd) else np.nan\n",
        "        cut_vals[p].append(cut)\n",
        "        dup_rej[p].append(np.mean(dist[dup] < cut)*100 if (np.any(dup) and not np.isnan(cut)) else np.nan)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "h = ax.hist2d(abs_eta[y_test==1], dist[y_test==1],\n",
        "              bins=[eta_edges, 50], norm=LogNorm())\n",
        "fig.colorbar(h[3], ax=ax, label='Counts')\n",
        "ax.set_xlabel('|η| (pLS)')\n",
        "ax.set_ylabel('Embedding distance')\n",
        "ax.set_title('pLS-T5  •  Embedding distance vs |η|  (test non-duplicates)')\n",
        "\n",
        "mid_eta = eta_edges[:-1] + 0.5*np.diff(eta_edges)\n",
        "for p, clr in zip(percentiles, plt.cm.rainbow(np.linspace(0,1,len(percentiles)))):\n",
        "    ax.plot(mid_eta, cut_vals[p], '-o', color=clr, label=f'{p}% retention')\n",
        "ax.legend(); ax.grid(alpha=0.3); plt.show()\n",
        "\n",
        "for p in percentiles:\n",
        "    cuts = \", \".join(f\"{v:.4f}\" if not np.isnan(v) else \"nan\" for v in cut_vals[p])\n",
        "    rejs = \", \".join(f\"{v:.2f}\"  if not np.isnan(v) else \"nan\" for v in dup_rej[p])\n",
        "    print(f\"{p}%-cut:     {{ {cuts} }}\")\n",
        "    print(f\"  {p}%-dupRej: {{ {rejs} }}\")\n",
        "    print()\n",
        "eff = \", \".join(f\"{v:.2f}\" if not np.isnan(v) else \"nan\" for v in dr2_eff)\n",
        "rej = \", \".join(f\"{v:.2f}\" if not np.isnan(v) else \"nan\" for v in dr2_rejdup)\n",
        "print(f\"dR2-eff  (%): {{ {eff} }}\")\n",
        "print(f\"dR2-dupRej (%): {{ {rej} }}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qpxp-zlQ7eXZ"
      },
      "outputs": [],
      "source": [
        "def print_formatted_weights_biases(weights, biases, layer_name):\n",
        "    # Print biases\n",
        "    print(f\"HOST_DEVICE_CONSTANT float bias_{layer_name}[{len(biases)}] = {{\")\n",
        "    print(\", \".join(f\"{b:.7f}f\" for b in biases) + \" };\")\n",
        "    print()\n",
        "\n",
        "    # Print weights\n",
        "    print(f\"HOST_DEVICE_CONSTANT const float wgtT_{layer_name}[{len(weights[0])}][{len(weights)}] = {{\")\n",
        "    for row in weights.T:\n",
        "        formatted_row = \", \".join(f\"{w:.7f}f\" for w in row)\n",
        "        print(f\"{{ {formatted_row} }},\")\n",
        "    print(\"};\")\n",
        "    print()\n",
        "\n",
        "def print_model_weights_biases(model):\n",
        "    # Make sure the model is in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Iterate through all named modules in the model\n",
        "    for name, module in model.named_modules():\n",
        "        # Check if the module is a linear layer\n",
        "        if isinstance(module, nn.Linear):\n",
        "            # Get weights and biases\n",
        "            weights = module.weight.data.cpu().numpy()\n",
        "            biases = module.bias.data.cpu().numpy()\n",
        "\n",
        "            # Print formatted weights and biases\n",
        "            print_formatted_weights_biases(weights, biases, name.replace('.', '_'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53oEEEhX7eXa"
      },
      "outputs": [],
      "source": [
        "print_model_weights_biases(embed_pls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvG5Q4z57eXa"
      },
      "outputs": [],
      "source": [
        "print_model_weights_biases(embed_t5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BIMHaWt7eXa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "analysisenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}